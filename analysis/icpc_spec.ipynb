{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b83d71-46f4-4a64-b586-527c91f85187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CAGE spectrum check\n",
    "# 13 Oct 2022\n",
    "\n",
    "# code sources -- CAGE/analysis/nplus.ipynb\n",
    "#              -- CAGE/processing/energy_raw.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a3680-fc93-4d6a-9d19-88f190aac229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, h5py, json, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "# use this to get interactive plots at NERSC.  \n",
    "# requires ipympl & jupyter-matplotlib extension for jupyterlab\n",
    "# user may need to $pip install ipympl --update\n",
    "%matplotlib widget\n",
    "# Successfully installed ipympl-0.9.2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas() # suppress annoying FutureWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5c6a0-689a-45f1-a123-d1d8dc9d3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pygama import DataGroup, lh5\n",
    "\n",
    "# imports for pygama tag v1.1.0, oct 2022.\n",
    "from pygama.flow import DataGroup as dg\n",
    "import pygama.lgdo.lh5_store as lh5\n",
    "import pygama.math.histogram as pgh\n",
    "    \n",
    "# import pygama.analysis.histograms as pgh\n",
    "# import pygama.analysis.peak_fitting as pgf\n",
    "\n",
    "# from pygama.dsp.dsp_optimize import *\n",
    "# from pygama.dsp.WaveformBrowser import WaveformBrowser as wfb\n",
    "# from pygama.io.hit_to_evt import cluster_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5881f0-70a0-4749-95c4-bdd06dddacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGroup('../processing/cage.json', load=True)    \n",
    "\n",
    "# que = 'cycle >=2563 and cycle <= 2565' # oppi in cage recently\n",
    "# que = 'run >= 414 and run <= 417' \n",
    "# que = 'run == 425'\n",
    "que = 'run == 430'\n",
    "\n",
    "df_cycles = dg.fileDB.query(que)\n",
    "\n",
    "# # df_runs.columns\n",
    "# # ['unique_key', 'YYYY', 'mm', 'dd', 'cycle', 'daq_dir', 'daq_file', 'run',\n",
    "# #        'runtype', 'detector', 'skip', 'dsp_id', 'raw_file', 'raw_path',\n",
    "# #        'dsp_file', 'dsp_path', 'hit_file', 'hit_path', 'startTime',\n",
    "# #        'threshold', 'daq_gb', 'stopTime', 'runtime']\n",
    "\n",
    "view = ['run','cycle','daq_file','startTime','threshold','daq_gb','runtime']\n",
    "df_cycles[view]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83189839-e53d-4d46-8b4c-6eee7511c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the first raw file and show the available LH5 tables and column names\n",
    "raw_files = dg.lh5_dir + df_cycles['raw_path'] + '/' + df_cycles['raw_file']\n",
    "\n",
    "# h5py has a funny way of iterating through groups, you have to pass 'visititems' a function\n",
    "def print_attrs(name, obj):\n",
    "    for key, val in obj.attrs.items():\n",
    "        if 'table' in val: # debug, only show tables.\n",
    "            print(name)\n",
    "            print(\"    %s: %s\" % (key, val))\n",
    "\n",
    "print('Raw file 0:')\n",
    "with h5py.File(raw_files.iloc[0]) as hf:\n",
    "    print(raw_files.iloc[0])\n",
    "    hf.visititems(print_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac68dd-6268-40f0-af15-3b5cf2e17da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load enough data to make an energy spectrum in both channels, and save some other interesting variables too\n",
    "\n",
    "def load_events(row, tb_name, data_cols, tb_type):\n",
    "    \"\"\"\n",
    "    I should add this function to DataGroup in pygama, it's like GATDataSet:GetGatifiedChain\n",
    "    \"\"\"\n",
    "    # print(row)\n",
    "    lh5_file = dg.lh5_dir + row[f'{tb_type}_path'] + '/' + row[f'{tb_type}_file']\n",
    "    lh5_data = pd.DataFrame(lh5.load_nda(lh5_file, data_cols, tb_name))\n",
    "    lh5_data['cycle'] = row['cycle']\n",
    "    return lh5_data\n",
    "\n",
    "# data_cols = ['channel','timestamp','energy','trapEmax','trapEftp','bl','bl_sig','bl_slope','bl_intercept',\n",
    "#              'wf_max','wf_argmax','tp_0','dcr','A_10','triE','hf_max','lf_max','tp_max']\n",
    "\n",
    "data_cols = ['energy','energy_first', 'timestamp']\n",
    "\n",
    "ncycles = 10\n",
    "tb_type = 'raw'\n",
    "etype = 'energy'\n",
    "\n",
    "# tmp = df_cycles[:ncycles].progress_apply(load_events, axis=1, args=('ORSIS3302DecoderForEnergy/raw', data_cols, tb_type,))\n",
    "\n",
    "tmp = df_cycles.progress_apply(load_events, axis=1, args=('ORSIS3302DecoderForEnergy/raw', data_cols, tb_type,))\n",
    "\n",
    "df_hits = pd.concat([df for df in tmp])\n",
    "print('In-memory size:', round(sys.getsizeof(df_hits) / 1024 / 1024, 2), \"MB\")\n",
    "\n",
    "# df_hits['energy'].max()\n",
    "df_hits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a780093-e515-4e7a-9774-d1929f795e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "\n",
    "# histogram energy data for this estimator -- TODO: and normalize by runtime\n",
    "\n",
    "# uncalibrated plot\n",
    "xlo, xhi, xpb = 0, 4e6, 10000   # good for energy\n",
    "data = df_hits[etype]\n",
    "hist, bins, var = pgh.get_hist(data, range=(xlo, xhi), dx=xpb)\n",
    "\n",
    "# # # rough calibrated plot.\n",
    "# elo, ehi, epb = 1, 250, 0.5 # 1--250 keV range\n",
    "elo, ehi, epb = 1, 2800, 0.5 \n",
    "\n",
    "# # run 414, one point calibration - 1460 keV = 1.954e6 in `energy`.\n",
    "# # cal = 1460 / 1.954e6\n",
    "cal = 1460 / 1.928e6\n",
    "# cal = 1460 / 1.830e6 # oppi in cage sep 2022\n",
    "data_cal = df_hits[etype] * cal\n",
    "hist, bins, var = pgh.get_hist(data_cal, range=(elo, ehi), dx=epb)\n",
    "\n",
    "bins = bins[1:] # trim zero bin, not needed with ds='steps'\n",
    "\n",
    "# hist_rt = np.divide(hist, runtime_min * 60)\n",
    "# print(f'\\nRaw E: {etype}, {len(data)} cts, runtime: {runtime_min:.2f} min')\n",
    "\n",
    "plt.semilogy(bins, hist, ds='steps', c='b', lw=1, label=etype)\n",
    "# plt.plot(bins, hist, ds='steps', c='b', lw=1, label=etype)\n",
    "\n",
    "plt.xlabel(etype, ha='right', x=1)\n",
    "# plt.ylabel(f'cts/sec, {xpb}/bin', ha='right', y=1)\n",
    "plt.ylabel('counts', ha='right', y=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd901f7-a929-4572-841b-6a19af0496ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legend-base",
   "language": "python",
   "name": "legend-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
