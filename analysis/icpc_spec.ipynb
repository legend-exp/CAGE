{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b83d71-46f4-4a64-b586-527c91f85187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CAGE spectrum check\n",
    "# 13 Oct 2022\n",
    "\n",
    "# code sources -- CAGE/analysis/nplus.ipynb\n",
    "#              -- CAGE/processing/energy_raw.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6a3680-fc93-4d6a-9d19-88f190aac229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21510/4115107063.py:6: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n"
     ]
    }
   ],
   "source": [
    "import os, sys, h5py, json, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "# use this to get interactive plots at NERSC.  \n",
    "# requires ipympl & jupyter-matplotlib extension for jupyterlab\n",
    "# user may need to $pip install ipympl --update\n",
    "# %matplotlib widget\n",
    "# Successfully installed ipympl-0.9.2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas() # suppress annoying FutureWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf5c6a0-689a-45f1-a123-d1d8dc9d3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pygama import DataGroup, lh5\n",
    "\n",
    "# imports for pygama tag v1.1.0, oct 2022.\n",
    "from pygama.flow import DataGroup\n",
    "import pygama.lgdo.lh5_store as lh5\n",
    "import pygama.math.histogram as pgh\n",
    "    \n",
    "# import pygama.analysis.histograms as pgh\n",
    "# import pygama.analysis.peak_fitting as pgf\n",
    "\n",
    "# from pygama.dsp.dsp_optimize import *\n",
    "# from pygama.dsp.WaveformBrowser import WaveformBrowser as wfb\n",
    "# from pygama.io.hit_to_evt import cluster_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5881f0-70a0-4749-95c4-bdd06dddacc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, DAQ directory not found: $CAGE_DAQ\n",
      "Warning, LH5 directory not found: $CAGE_LH5\n",
      "Warning, LH5 user directory not found: $CAGE_LH5_USER\n",
      "Warning, run selection file not found: $CAGE_SW/processing/metadata/run_selection.json\n",
      "environ({'LEGENDDATADIR': '/global/project/projectdirs/m2676/data', 'PYTHONUNBUFFERED': '1', 'PYTHONIOENCODING': 'utf-8', 'SHIFTER_IMAGEREQUEST': 'legendexp/legend-base:latest', 'SHIFTER_IMAGE': '00d58d1bb58f22ae23b4d4c65f29bff8209f2c86a92a197a8b6ae300cf4dcff4', 'PATH': '/opt/root/bin:/opt/geant4/bin:/opt/clhep/bin:/opt/hdf5/bin:/opt/nodejs/bin:/opt/anaconda3/bin:/opt/anaconda3/condabin:/opt/julia/bin:/opt/julia-1.9/bin:/opt/julia-1.8/bin:/opt/julia-1.6/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/udiImage/bin', 'NVARCH': 'x86_64', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.7 brand=tesla,driver>=450,driver<451 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=510,driver<511 brand=unknown,driver>=510,driver<511 brand=nvidia,driver>=510,driver<511 brand=nvidiartx,driver>=510,driver<511 brand=quadro,driver>=510,driver<511 brand=quadrortx,driver>=510,driver<511 brand=titan,driver>=510,driver<511 brand=titanrtx,driver>=510,driver<511 brand=geforce,driver>=510,driver<511 brand=geforcertx,driver>=510,driver<511', 'NV_CUDA_CUDART_VERSION': '11.7.60-1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-7', 'CUDA_VERSION': '11.7.0', 'LD_LIBRARY_PATH': '/opt/udiImage/modules/mpich/mpich-7.7.19/lib64:/opt/udiImage/modules/mpich/mpich-7.7.19/lib64/dep:/opt/root/lib:/opt/geant4/lib:/opt/clhep/lib:/opt/hdf5/lib:/usr/local/cuda/lib64:/usr/local/cuda/nvvm/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NVIDIA_VISIBLE_DEVICES': 'all', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NV_CUDA_LIB_VERSION': '11.7.0-1', 'NV_NVTX_VERSION': '11.7.50-1', 'NV_LIBNPP_VERSION': '11.7.3.21-1', 'NV_LIBNPP_PACKAGE': 'libnpp-11-7=11.7.3.21-1', 'NV_LIBCUSPARSE_VERSION': '11.7.3.50-1', 'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-11-7', 'NV_LIBCUBLAS_VERSION': '11.10.1.25-1', 'NV_LIBCUBLAS_PACKAGE': 'libcublas-11-7=11.10.1.25-1', 'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2', 'NV_LIBNCCL_PACKAGE_VERSION': '2.13.4-1', 'NCCL_VERSION': '2.13.4-1', 'NV_LIBNCCL_PACKAGE': 'libnccl2=2.13.4-1+cuda11.7', 'NVIDIA_PRODUCT_NAME': 'CUDA', 'NVIDIA_CUDA_END_OF_LIFE': '1', 'NV_CUDA_CUDART_DEV_VERSION': '11.7.60-1', 'NV_NVML_DEV_VERSION': '11.7.50-1', 'NV_LIBCUSPARSE_DEV_VERSION': '11.7.3.50-1', 'NV_LIBNPP_DEV_VERSION': '11.7.3.21-1', 'NV_LIBNPP_DEV_PACKAGE': 'libnpp-dev-11-7=11.7.3.21-1', 'NV_LIBCUBLAS_DEV_VERSION': '11.10.1.25-1', 'NV_LIBCUBLAS_DEV_PACKAGE_NAME': 'libcublas-dev-11-7', 'NV_LIBCUBLAS_DEV_PACKAGE': 'libcublas-dev-11-7=11.10.1.25-1', 'NV_NVPROF_VERSION': '11.7.50-1', 'NV_NVPROF_DEV_PACKAGE': 'cuda-nvprof-11-7=11.7.50-1', 'NV_LIBNCCL_DEV_PACKAGE_NAME': 'libnccl-dev', 'NV_LIBNCCL_DEV_PACKAGE_VERSION': '2.13.4-1', 'NV_LIBNCCL_DEV_PACKAGE': 'libnccl-dev=2.13.4-1+cuda11.7', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'NV_CUDNN_VERSION': '8.5.0.96', 'NV_CUDNN_PACKAGE_NAME': 'libcudnn8', 'NV_CUDNN_PACKAGE': 'libcudnn8=8.5.0.96-1+cuda11.7', 'NV_CUDNN_PACKAGE_DEV': 'libcudnn8-dev=8.5.0.96-1+cuda11.7', 'JULIA_CUDA_USE_BINARYBUILDER': 'false', 'MANPATH': '/opt/root/man:/opt/nodejs/share/man:/opt/anaconda3/share/man:/opt/julia/share/man:', 'CONDA_EXE': '/opt/anaconda3/bin/conda', 'CONDA_PREFIX': '/opt/anaconda3', 'CONDA_PYTHON_EXE': '/opt/anaconda3/bin/python', 'PYTHON': 'python3', 'JUPYTER': 'jupyter', 'JAVA_HOME': '/usr/lib/jvm/java-11-openjdk-amd64', 'LESSOPEN': '||/usr/bin/lesspipe.sh %s', 'G4ABLADATA': '/opt/geant4/share/Geant4-10.5.1/data/G4ABLA3.1', 'G4ENSDFSTATEDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4ENSDFSTATE2.2', 'G4INCLDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4INCL1.0', 'G4LEDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4EMLOW7.7', 'G4LEVELGAMMADATA': '/opt/geant4/share/Geant4-10.5.1/data/PhotonEvaporation5.3', 'G4NEUTRONHPDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4NDL4.5', 'G4PARTICLEXSDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4PARTICLEXS1.1', 'G4PIIDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4PII1.3', 'G4RADIOACTIVEDATA': '/opt/geant4/share/Geant4-10.5.1/data/RadioactiveDecay5.3', 'G4REALSURFACEDATA': '/opt/geant4/share/Geant4-10.5.1/data/RealSurface2.1.1', 'G4SAIDXSDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4SAIDDATA2.0', 'AllowForHeavyElements': '1', 'G4TENDLDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4TENDL1.3.2', 'G4PARTICLEHPDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4TENDL1.3.2', 'G4PROTONHPDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4TENDL1.3.2/Proton', 'G4DEUTERONHPDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4TENDL1.3.2/Deuteron', 'G4TRITONHPDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4TENDL1.3.2/Triton', 'G4HE3HPDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4TENDL1.3.2/He3', 'G4ALPHAHPDATA': '/opt/geant4/share/Geant4-10.5.1/data/G4TENDL1.3.2/Alpha', 'PYTHONPATH': '/opt/mods/lib/python3.6/site-packages:/opt/root/lib:', 'CMAKE_PREFIX_PATH': '/opt/root;', 'JUPYTER_PATH': '/opt/root/etc/notebook:', 'ROOTSYS': '/opt/root', 'JULIA_CXX_RTTI': '1', 'SWMOD_HOSTSPEC': 'linux-ubuntu-20.04-x86_64-470e63d7', 'SHIFTER_MODULE_MPICH': '1', 'SHIFTER_RUNTIME': '1', 'LC_CTYPE': 'C.UTF-8', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline'})\n",
      "$CAGE_SW/processing/fileDB.h5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File $CAGE_SW/processing/fileDB.h5 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21510/3324033102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../processing/cage.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# que = 'cycle >=2563 and cycle <= 2565' # oppi in cage recently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# que = 'run >= 414 and run <= 417'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mque\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'run == 425'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/g/grsong/legend/pygama/src/pygama/flow/datagroup.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, nfiles, load)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# load a pre-existing set of keys.  should be True by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/g/grsong/legend/pygama/src/pygama/flow/datagroup.py\u001b[0m in \u001b[0;36mload_df\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpandvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileDB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpandvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'file_keys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {path_or_buf} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File $CAGE_SW/processing/fileDB.h5 does not exist"
     ]
    }
   ],
   "source": [
    "dg = DataGroup('../processing/cage.json', load=True)    \n",
    "\n",
    "# que = 'cycle >=2563 and cycle <= 2565' # oppi in cage recently\n",
    "# que = 'run >= 414 and run <= 417' \n",
    "que = 'run == 425'\n",
    "# que = 'run == 430'\n",
    "\n",
    "df_cycles = dg.fileDB.query(que)\n",
    "\n",
    "# # df_runs.columns\n",
    "# # ['unique_key', 'YYYY', 'mm', 'dd', 'cycle', 'daq_dir', 'daq_file', 'run',\n",
    "# #        'runtype', 'detector', 'skip', 'dsp_id', 'raw_file', 'raw_path',\n",
    "# #        'dsp_file', 'dsp_path', 'hit_file', 'hit_path', 'startTime',\n",
    "# #        'threshold', 'daq_gb', 'stopTime', 'runtime']\n",
    "\n",
    "view = ['run','cycle','daq_file','startTime','threshold','daq_gb']\n",
    "display(df_cycles[view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83189839-e53d-4d46-8b4c-6eee7511c5ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48565/1265700234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check the first raw file and show the available LH5 tables and column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mraw_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlh5_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf_cycles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf_cycles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# h5py has a funny way of iterating through groups, you have to pass 'visititems' a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dg' is not defined"
     ]
    }
   ],
   "source": [
    "# check the first raw file and show the available LH5 tables and column names\n",
    "raw_files = dg.lh5_dir + df_cycles['raw_path'] + '/' + df_cycles['raw_file']\n",
    "\n",
    "# h5py has a funny way of iterating through groups, you have to pass 'visititems' a function\n",
    "def print_attrs(name, obj):\n",
    "    for key, val in obj.attrs.items():\n",
    "        if 'table' in val: # debug, only show tables.\n",
    "            print(name)\n",
    "            print(\"    %s: %s\" % (key, val))\n",
    "\n",
    "print('Raw file 0:')\n",
    "with h5py.File(raw_files.iloc[0]) as hf:\n",
    "    print(raw_files.iloc[0])\n",
    "    hf.visititems(print_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaac68dd-6268-40f0-af15-3b5cf2e17da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cycles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48565/3737170231.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0metype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'energy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cycles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mncycles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ORSIS3302DecoderForEnergy/raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# tmp = df_cycles.progress_apply(load_events, axis=1, args=('ORSIS3302DecoderForEnergy/raw', data_cols, tb_type,))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cycles' is not defined"
     ]
    }
   ],
   "source": [
    "# load enough data to make an energy spectrum in both channels, and save some other interesting variables too\n",
    "\n",
    "def load_events(row, tb_name, data_cols, tb_type):\n",
    "    \"\"\"\n",
    "    I should add this function to DataGroup in pygama, it's like GATDataSet:GetGatifiedChain\n",
    "    \"\"\"\n",
    "    # print(row)\n",
    "    lh5_file = dg.lh5_dir + row[f'{tb_type}_path'] + '/' + row[f'{tb_type}_file']\n",
    "    lh5_data = pd.DataFrame(lh5.load_nda(lh5_file, data_cols, tb_name))\n",
    "    lh5_data['cycle'] = row['cycle']\n",
    "    return lh5_data\n",
    "\n",
    "# data_cols = ['channel','timestamp','energy','trapEmax','trapEftp','bl','bl_sig','bl_slope','bl_intercept',\n",
    "#              'wf_max','wf_argmax','tp_0','dcr','A_10','triE','hf_max','lf_max','tp_max']\n",
    "\n",
    "data_cols = ['energy','energy_first', 'timestamp']\n",
    "\n",
    "ncycles = 10\n",
    "tb_type = 'raw'\n",
    "etype = 'energy'\n",
    "\n",
    "tmp = df_cycles[:ncycles].progress_apply(load_events, axis=1, args=('ORSIS3302DecoderForEnergy/raw', data_cols, tb_type,))\n",
    "\n",
    "# tmp = df_cycles.progress_apply(load_events, axis=1, args=('ORSIS3302DecoderForEnergy/raw', data_cols, tb_type,))\n",
    "\n",
    "df_hits = pd.concat([df for df in tmp])\n",
    "print('In-memory size:', round(sys.getsizeof(df_hits) / 1024 / 1024, 2), \"MB\")\n",
    "\n",
    "# df_hits['energy'].max()\n",
    "df_hits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a780093-e515-4e7a-9774-d1929f795e7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_hits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48565/2700077424.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# uncalibrated plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mxlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4e6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m   \u001b[0;31m# good for energy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_hits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_hits' is not defined"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "\n",
    "\n",
    "# histogram energy data for this estimator -- TODO: and normalize by runtime\n",
    "\n",
    "# uncalibrated plot\n",
    "xlo, xhi, xpb = 0, 4e6, 10000   # good for energy\n",
    "data = df_hits[etype]\n",
    "hist, bins, var = pgh.get_hist(data, range=(xlo, xhi), dx=xpb)\n",
    "\n",
    "# # # rough calibrated plot.\n",
    "# elo, ehi, epb = 1, 250, 0.5 # 1--250 keV range\n",
    "elo, ehi, epb = 1, 2800, 0.5 \n",
    "\n",
    "# # run 414, one point calibration - 1460 keV = 1.954e6 in `energy`.\n",
    "# # cal = 1460 / 1.954e6\n",
    "cal = 1460 / 1.928e6\n",
    "# cal = 1460 / 1.830e6 # oppi in cage sep 2022\n",
    "data_cal = df_hits[etype] * cal\n",
    "hist, bins, var = pgh.get_hist(data_cal, range=(elo, ehi), dx=epb)\n",
    "\n",
    "bins = bins[1:] # trim zero bin, not needed with ds='steps'\n",
    "\n",
    "# hist_rt = np.divide(hist, runtime_min * 60)\n",
    "# print(f'\\nRaw E: {etype}, {len(data)} cts, runtime: {runtime_min:.2f} min')\n",
    "\n",
    "plt.semilogy(bins, hist, ds='steps', c='b', lw=1, label=etype)\n",
    "# plt.plot(bins, hist, ds='steps', c='b', lw=1, label=etype)\n",
    "\n",
    "plt.xlabel(etype, ha='right', x=1)\n",
    "# plt.ylabel(f'cts/sec, {xpb}/bin', ha='right', y=1)\n",
    "plt.ylabel('counts', ha='right', y=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd901f7-a929-4572-841b-6a19af0496ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legend-base",
   "language": "python",
   "name": "legend-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
