{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Always Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import chi2\n",
    "from scipy.optimize import curve_fit\n",
    "from pygama.flow import DataLoader\n",
    "from pygama.flow import FileDB\n",
    "from lgdo import Array\n",
    "from lgdo import Struct\n",
    "from lgdo import LH5Store\n",
    "from pygama.math import histogram as pgh\n",
    "from pygama.math import peak_fitting as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"font.family\"] = \"serif\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FileDB and DataLoader Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdb = FileDB(config=\"../processing/metadata/dataloader_configs/cage_filedb_config.json\", scan=True)\n",
    "fdb.scan_tables_columns()\n",
    "fdb.to_disk(\"../processing/cage_filedb.lh5\", \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl = DataLoader(config=\"../processing/metadata/dataloader_configs/cage_loader_config.json\",\n",
    "                filedb=fdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdb = FileDB(\"../processing/cage_filedb.lh5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdb.config['tier_dirs']['raw'] = 'raw'\n",
    "fdb.config['tier_dirs']['dsp'] = 'dsp'\n",
    "fdb.config['tier_dirs']['hit'] = 'hit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdb.set_config(fdb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdb.sortby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this if FDB needs to be updated and then re-saved to disk\n",
    "og_col = fdb.columns\n",
    "fdb.scan_files()\n",
    "fdb.set_file_status()\n",
    "fdb.set_file_sizes()\n",
    "fdb.scan_tables_columns()\n",
    "assert fdb.columns == og_col\n",
    "fdb.to_disk(\"../processing/cage_filedb.lh5\", \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl = DataLoader(config=\"../processing/metadata/dataloader_configs/cage_loader_config.json\",\n",
    "                filedb=fdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stolen from Clint\n",
    "# Fit functions\n",
    "from scipy.special import erfc, legendre\n",
    "\n",
    "# Component functions for the peak shape\n",
    "def gaus(E, A, f_le, mu, sig, f_he):\n",
    "    \"\"\"\n",
    "    A: total number of counts (i.e. peak area)\n",
    "    mu, sig : gaussian\n",
    "    f_le, f_he : fraction of low E and high E tail components\n",
    "    \"\"\"\n",
    "    # assert np.abs(f_le + f_he) <= 1, 'Tail fractions cant be larger than 1'\n",
    "    norm = A * (1 - f_he - f_le) / (np.sqrt(2*np.pi) * sig)\n",
    "    return norm * np.exp(-(E-mu)**2 / (2 * sig**2))\n",
    "\n",
    "\n",
    "def tail(E, A, mu, sig, f, gamma, alpha):\n",
    "    \"\"\"\n",
    "    gamma : decay constant of the tail exponential\n",
    "    \"\"\"\n",
    "    assert alpha == 1 or alpha == -1, 'alpha is the sign choice +/- 1'\n",
    "    norm = A * f / (2 * gamma)\n",
    "    expo = np.exp((sig**2) / (2*gamma**2) + alpha * ((E-mu) / gamma))\n",
    "    erf = erfc((sig) / (np.sqrt(2)*gamma) + alpha * ( (E-mu) / (np.sqrt(2)*sig) ))\n",
    "    return norm * expo * erf\n",
    "\n",
    "def step(E, A, H, mu, sig):\n",
    "    \"\"\"\n",
    "    H : height of step bkg as a fraction of the peak area\n",
    "    \"\"\"\n",
    "    norm = A * H / 2\n",
    "    erf = erfc( (E - mu) / (np.sqrt(2)*sig) )\n",
    "    return norm * erf\n",
    "\n",
    "def bkg_legendre(E, q, m, b, E_cen, elo):\n",
    "    \"\"\"\n",
    "    sum of legendre polynomials, making a quadratic, linear, or flat function.\n",
    "    for linear bkg, q = 0.  for flat bkg, q = m = 0.\n",
    "    FIXME, DONTUSE: need to scale-shift the x limits [-1, 1] to the fit window [elo, ehi].\n",
    "    - This is not necessary for our PEPV-1A analysis, a linear bkg is sufficient.\n",
    "    \"\"\"\n",
    "    # these are np.poly1d objects defined on [-1, 1]\n",
    "    legP2 = legendre(2) # = 1.5 * x - 0.5\n",
    "    legP1 = legendre(1) # = x\n",
    "    return q * legP2(E - E_cen) + m * legP1(E - E_cen) + b\n",
    "\n",
    "def bkg_simple(E, q, m, b):\n",
    "    \"\"\"\n",
    "    Use this instead.\n",
    "    \"\"\"\n",
    "    return q * E**2 + m * E + b\n",
    "\n",
    "# Composite functions for the peak shape + bkg + echo peak\n",
    "def peakshape(E, A, mu, sig, f, gamma, H, q, m, b):\n",
    "    \"\"\"\n",
    "    This is bkg peak (main peak) plus background, written to match the Majorana 2023 calibration paper.\n",
    "    Includes a term for the background function, which will also cover the echo peak region.\n",
    "    \n",
    "    SIX floating terms per peak are needed, with ONE to THREE more for the bkg polynomial.\n",
    "    In reality these terms all depend on energy & vary with energy,\n",
    "    but the parameterization (eqs. 2.7-2.14) can be ignored for this DEP/SEP analysis.\n",
    "    \n",
    "    NOTE: The low energy tail was reduced, and the high energy tail made negligible, \n",
    "    through optimizations in energy estimation described in [26].\n",
    "    \"\"\"\n",
    "    G = gaus(E, A, f, mu, sig, 0) # fix f_he to 0\n",
    "    T_low = tail(E, A, mu, sig, f, gamma, 1) # alpha = 1 for LE, -1 for HE\n",
    "    # T_high = tail(E, A, mu, sig, f_he, gamma_he, -1) # not used\n",
    "    S = step(E, A, H, mu, sig)\n",
    "    # B = bkg_legendre(E, E_cen, q, m, b) # not used\n",
    "    B = bkg_simple(E, q, m, b)\n",
    "    return G + T_low + S + B\n",
    "\n",
    "def peak_only(E, A, mu, sig, f, gamma, H):\n",
    "    \"\"\"\n",
    "    Use this to model the echo peak\n",
    "    \"\"\"\n",
    "    G = gaus(E, A, f, mu, sig, 0)\n",
    "    T_low = tail(E, A, mu, sig, f, gamma, 1)\n",
    "    S = step(E, A, H, mu, sig)\n",
    "    return G + T_low + S\n",
    "\n",
    "def peak_plus_echo(E, branching_ratio, A, mu, sig, f, gamma, H, q, m, b):\n",
    "    \"\"\"\n",
    "    This is the main peak plus the echo peak. The 'branching ratio' gives the relative ratio of the two. \n",
    "    They share the same parameters except the height and the location.\n",
    "    \"\"\"\n",
    "    y_bkg = peakshape(E, A, mu, sig, f, gamma, H, q, m, b)\n",
    "    y_echo = peak_only(E, A * branching_ratio, mu + 10.6, sig, f, gamma, H)\n",
    "    y_total = y_bkg + y_echo\n",
    "    return y_total\n",
    "\n",
    "def negativeloglikelihood(branching_ratio, A, mu, sig, f, gamma, f_he, H, q, m, b):\n",
    "    \"\"\"\n",
    "    Wilks' theorem: 2 * NLL goes as a chi^2 distribution.\n",
    "    1. At each bin, get the probability of having n counts (n is from data) from m expected (m is from the model). \n",
    "       This is done by assuming the Poisson statistics.\n",
    "    2. Take the logarithm, and sum them up over the entire fit range. (summation is from i=1 up to i=number_of_bins)\n",
    "    3. Multiply by -1 to get negative log-likelihood.  \n",
    "    \"\"\"\n",
    "    yfit = peak_plus_echo(x, branching_ratio, A, mu, sig, f, gamma, f_he, H, q, m, b)\n",
    "    probs = poisson.pmf(y, yfit) # step 1\n",
    "    nll = -np.sum(np.log(probs)) # step 2 and step 3\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def get_runtime(data):\n",
    "    '''\n",
    "    Returns runtime for a run\n",
    "    '''\n",
    "    if 'timestamp' not in data.keys():\n",
    "        return np.sum([get_runtime(data[key]) for key in data.keys()])\n",
    "    clock = 100e6 # 100 MHz\n",
    "\n",
    "    ts = data['timestamp'].nda / clock # converts to float\n",
    "    \n",
    "    rt = ts[-1] - ts[0]\n",
    "\n",
    "    return rt \n",
    "\n",
    "\n",
    "\n",
    "# compute some stats\n",
    "# ref: slide 3, https://www.nbi.dk/~petersen/Teaching/Stat2016/Week7/AS2016_0109_AdvancedFitting.pdf\n",
    "def get_chisquare(hh, y_model, sr_pars, cl=0.9):\n",
    "    ndf = len(hh) - len(sr_pars) \n",
    "    chisquare = np.sum((hh - y_model)**2 / y_model) # pearson.  no one likes neyman.\n",
    "    chisquare_ndf = chisquare / ndf\n",
    "    p_value = chi2.sf(chisquare, ndf)\n",
    "    hyp_rej = p_value < (1-cl) # if True, we have a BAD fit - the model DOESN'T describe the data.\n",
    "    goodfit = 'T' if not hyp_rej else 'F'\n",
    "    return chisquare_ndf, p_value, hyp_rej, goodfit\n",
    "\n",
    "\n",
    "def fit_peak(hist, ebins, guess, plot=False, n_bins=40, max_attempts = 3, recursed=False, cl=1 - 1e-5):\n",
    "    '''\n",
    "    Attempts to fit the histogram near guess (given in units of ebins, not index) \n",
    "    If the fit is not great, will try again with different number of bins to fit over up to max_attempts times\n",
    "    '''\n",
    "    ebin_centers = pgh.get_bin_centers(ebins)\n",
    "    guess_idx = np.argmin(np.abs(ebins - guess))\n",
    "    glo = guess_idx - int(n_bins)\n",
    "    ghi = guess_idx + int(n_bins)\n",
    "    \n",
    "    thresh = (np.average(hist[glo:glo+10]) + np.average(hist[ghi-10 : ghi]) ) / 2\n",
    "    \n",
    "    peaks, p_props = find_peaks(hist[glo : ghi], height=thresh)\n",
    "    \n",
    "    peak_idx = peaks[np.argmax(p_props['peak_heights'])] + glo\n",
    "    lo = peak_idx - int(n_bins/2)\n",
    "    hi = peak_idx + int(n_bins/2)\n",
    "    \n",
    "    init = {'A': hist[lo:hi].sum(), \n",
    "            'mu': ebin_centers[peak_idx], \n",
    "            'sig': (ebins[hi]-ebins[lo])/5, \n",
    "            'f_le': 0.14,\n",
    "            'gamma': 1.02, \n",
    "            'H' : 0.01, \n",
    "            'q': -0.0001, \n",
    "            'm': 0.01, \n",
    "            'b': 1000,\n",
    "            }\n",
    "    sr_par0 = pd.Series(init)\n",
    "    bounds_dep = {  \n",
    "        'A' : [0, hist.sum()],\n",
    "        'mu' : [ebin_centers[lo], ebin_centers[hi]],\n",
    "        'sig' : [0, 20], \n",
    "        'f_le' : [0, 1],\n",
    "        'gamma' : [0, np.inf],\n",
    "        'H': [0, 1],\n",
    "        'q' : [-np.inf, np.inf], # don't bound these, we want them to be as good as possible\n",
    "        'm' : [-np.inf, np.inf],\n",
    "        'b' : [-np.inf, np.inf]\n",
    "    }\n",
    "    sr_bounds0 = pd.Series(bounds_dep)\n",
    "    \n",
    "    # curve_fit requires a 2-tuple of array_like.  bounds = ((lower), (upper)).\n",
    "    # each element of the tuple must be either an array with the length equal to the number of parameters.\n",
    "    bnd_lo, bnd_hi = [], []\n",
    "    for key in sr_par0.index:\n",
    "        if key in sr_bounds0.index:\n",
    "            bnd_lo.append(sr_bounds0[key][0])\n",
    "            bnd_hi.append(sr_bounds0[key][1])\n",
    "            \n",
    "    try:\n",
    "        popt, pcov = curve_fit(peakshape, ebin_centers[lo:hi], hist[lo:hi], p0=sr_par0, bounds=(bnd_lo, bnd_hi))\n",
    "        chisq, _, hyp_rej, _ = get_chisquare(hist[lo:hi], peakshape(ebin_centers[lo:hi], *popt), popt, cl=cl)\n",
    "    except RuntimeError:\n",
    "        popt = sr_par0\n",
    "        pcov = None\n",
    "        chisq = 1e5\n",
    "        hyp_rej = True\n",
    "    \n",
    "    if recursed:\n",
    "        return popt, pcov, lo, hi\n",
    "    \n",
    "    n_attempts = 0\n",
    "    n_bins_attempts = [f(x) for x in np.arange(max_attempts)+1 for f in (lambda x: n_bins + 10*x, lambda x: n_bins - 10*x)]\n",
    "    while n_attempts < max_attempts and hyp_rej: \n",
    "        # print(\"Trying again...\")\n",
    "        g_popt, g_pcov, g_lo, g_hi = fit_peak(hist, ebins, popt[1], plot=False, n_bins=n_bins_attempts[n_attempts], recursed=True)\n",
    "        g_chisq, _, g_hyp_rej, _ = get_chisquare(hist[lo:hi], peakshape(ebin_centers[lo:hi], *g_popt), g_popt, cl=cl)\n",
    "        l_popt, l_pcov, l_lo, l_hi = fit_peak(hist, ebins, popt[1], plot=False, n_bins=n_bins_attempts[n_attempts + 1], recursed=True)\n",
    "        l_chisq, _, l_hyp_rej, _ = get_chisquare(hist[lo:hi], peakshape(ebin_centers[lo:hi], *l_popt), l_popt, cl=cl)\n",
    "        \n",
    "        choices = [(popt, pcov, hyp_rej, lo, hi), (g_popt, g_pcov, g_hyp_rej, g_lo, g_hi), (l_popt, l_pcov, l_hyp_rej, l_lo, l_hi)]\n",
    "        choice = np.argmin([chisq, g_chisq, l_chisq])\n",
    "        # str_choices = [\"old\", \"bigger\", \"smaller\"]\n",
    "        # print(f\"Best was {str_choices[choice]}\")\n",
    "        popt, pcov, hyp_rej, lo, hi = choices[choice]\n",
    "        n_attempts += 1    \n",
    "    \n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        pgh.plot_hist(hist[lo-10 : hi+10], ebins[lo-10 : hi + 11])\n",
    "        plt.plot(ebin_centers[lo:hi], peakshape(ebins[lo:hi], *sr_par0), label=\"initial\")\n",
    "        plt.plot(ebin_centers[lo:hi], peakshape(ebins[lo:hi], *popt), label=\"fit\")\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "    \n",
    "    return popt, pcov, hyp_rej\n",
    "\n",
    "def calibrate_energy(energy, ebins, plot=False):\n",
    "    '''\n",
    "    Makes energy histogram, then fits the 1460 keV peak\n",
    "    Simple linear scaling to get the calibrated energies\n",
    "    '''\n",
    "    hist, _ = np.histogram(energy, ebins)\n",
    "    \n",
    "    third = int(len(ebins)/3)\n",
    "    k40_idx = np.argmax(hist[third:]) + third\n",
    "            \n",
    "    popt, pcov, hyp_rej = fit_peak(hist, ebins, ebins[k40_idx], plot=plot)\n",
    "    \n",
    "    k40_mu = popt[1]\n",
    "    return np.array(energy*1460.8/k40_mu), 1460.8/k40_mu\n",
    "\n",
    "def calibrate_toe(toe, toe_bins, plot=False, scale=True):\n",
    "    '''\n",
    "    Makes T/E histogram, then gets the mode for peak position\n",
    "        scale: if true, divide by the mode and then subtract 1\n",
    "                if false, just subtract the mode\n",
    "    '''\n",
    "    hist, _ = np.histogram(toe, toe_bins)\n",
    "    mode = pgh.get_bin_centers(toe_bins)[np.argmax(hist)]\n",
    "    \n",
    "    if scale:\n",
    "        return np.array(toe/mode) - 1, mode\n",
    "    else:\n",
    "        return np.array(toe - mode), mode\n",
    "\n",
    "ebins = np.linspace(0, 7000, 12000)\n",
    "cal_ebins = np.linspace(0, 5000, 10000)\n",
    "dcr_bins = np.arange(-50, 200)\n",
    "tp20_bins = np.arange(0, 1500, 10)\n",
    "tp90_bins = np.arange(0, 1500, 10)\n",
    "toe_bins = np.linspace(0, 1, 500)\n",
    "aoe_bins = np.linspace(0, 0.1, 1000)\n",
    "cal_toe_bins = np.linspace(-1, 1, 500)\n",
    "lt_bins = np.linspace(-2.5e-4, -0.5e-4, 1000)\n",
    "\n",
    "bins = {\n",
    "    \"trapEmax_ctc\": ebins,\n",
    "    \"cal_trapEmax_ctc\": cal_ebins,\n",
    "    \"dcr\": dcr_bins,\n",
    "    \"tp_20\": tp20_bins,\n",
    "    \"tp_90\": tp90_bins,\n",
    "    \"ToE\": toe_bins,\n",
    "    \"AoE\": aoe_bins,\n",
    "    \"cal_ToE\": cal_toe_bins,\n",
    "    \"lt_slope\": lt_bins\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to set up some information that's going to make looking up information easier as we do analysis. This is going to look kind of like a section of the RunDB, but in table format. It's also going to include a column for which `dataset` the run is in i.e. if we're trying to compare two scans, does it belong in scan A or scan B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdb_cols = ['dataset', 'type', 'rotary', 'linear', 'source']\n",
    "runs = {\n",
    "    494: [0, 'bkg', 0, -2.5, 0], \n",
    "    495: [0, 'bkg', 0, -2.5, 0], \n",
    "    496: [0, 'alp', 0, 0, -180],\n",
    "    500: [0, 'alp', 0, 1, -180],\n",
    "    501: [0, 'alp', 0, 2, -180],\n",
    "    502: [0, 'alp', 0, 3, -180],\n",
    "    503: [0, 'alp', 0, 4, -180],\n",
    "    504: [0, 'alp', 0, 5, -180],\n",
    "    505: [0, 'alp', 0, 6, -180],\n",
    "    506: [0, 'alp', 0, 7, -180],\n",
    "    507: [0, 'alp', 0, 8, -180],\n",
    "    508: [0, 'alp', 0, 9, -180],\n",
    "    509: [0, 'alp', 0, 10, -180],\n",
    "    510: [0, 'alp', 0, 12, -180],\n",
    "    511: [0, 'alp', 0, 13, -180],\n",
    "    512: [0, 'alp', 0, 14, -180],\n",
    "    513: [0, 'alp', 0, 15, -180],\n",
    "    514: [0, 'alp', 0, 16, -180],\n",
    "    520: [1, 'bkg', 0, -2.5, 0],\n",
    "    521: [1, 'bkg', 0, -2.5, 0], \n",
    "    522: [1, 'bkg', 0, 16, 0], \n",
    "    523: [1, 'bkg', 0, 14, 0], \n",
    "    524: [1, 'bkg', 0, 12, 0], \n",
    "    525: [1, 'alp', 0, 10, -180], \n",
    "    526: [1, 'alp', 0, 8, -180], \n",
    "    527: [1, 'alp', 0, 6, -180], \n",
    "    528: [1, 'alp', 0, 4, -180], \n",
    "    529: [1, 'alp', 0, 2, -180], \n",
    "    530: [1, 'alp', 0, 0, -180],\n",
    "    531: [1, 'alp', 0, 12, -180],\n",
    "    532: [1, 'alp', 0, 14, -180],\n",
    "    533: [1, 'bkg', 0, 16, 0],\n",
    "    534: [1, 'alp', 0, 16, -180],\n",
    "    458: [2, 'alp', 0, 0, -180],\n",
    "    459: [2, 'alp', 0, 1, -180],\n",
    "    460: [2, 'alp', 0, 2, -180],\n",
    "    461: [2, 'alp', 0, 3, -180],\n",
    "    462: [2, 'alp', 0, 4, -180],\n",
    "    463: [2, 'alp', 0, 5, -180],\n",
    "    464: [2, 'alp', 0, 6, -180],\n",
    "    465: [2, 'alp', 0, 7, -180],\n",
    "    466: [2, 'alp', 0, 8, -180],\n",
    "    467: [2, 'alp', 0, 9, -180],\n",
    "    468: [2, 'alp', 0, 10, -180],\n",
    "    469: [2, 'alp', 0, 12, -180],\n",
    "    470: [2, 'alp', 0, 14, -180],\n",
    "    471: [2, 'bkg', 0, -2.5, 0],\n",
    "    433: [2, 'bkg', 0, -2.5, 0]\n",
    "    \n",
    "}\n",
    "rdb_df = pd.DataFrame.from_dict(runs, orient='index', columns=rdb_cols)\n",
    "rdb_df.sort_values(by=['dataset', 'type', 'rotary', 'linear', 'source'], inplace=True)\n",
    "display(rdb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdb_cols = ['dataset', 'type', 'rotary', 'linear', 'source']\n",
    "runs = {\n",
    "    471: [2, 'bkg', 0, -2.5, 0],\n",
    "    433: [2, 'bkg', 0, -2.5, 0]\n",
    "    \n",
    "}\n",
    "rdb_df = pd.DataFrame.from_dict(runs, orient='index', columns=rdb_cols)\n",
    "rdb_df.sort_values(by=['dataset', 'type', 'rotary', 'linear', 'source'], inplace=True)\n",
    "display(rdb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sto = LH5Store()\n",
    "loaded_file = \"icpc_scan_data.lh5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "par_names = [\"trapEmax_ctc\", \"dcr\", \"ToE\", \"timestamp\", \"tp_0\", \"tp_10\", \"tp_20\", \"tp_90\", \"lt_slope\", \"AoE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will call the DataLoader functions to grab the data from disk and save the relevant portions to a Struct in `loaded_file`. Alpha and background runs will be separated. \n",
    "\n",
    "Alpha data will be saved in a Struct, where the keys are run numbers.\n",
    "Background data will not be separated by run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    print(f\"Loading dataset {ds}\")\n",
    "    if ds not in data.keys():\n",
    "        data[ds] = {}\n",
    "    for t, t_df in ds_df.groupby(by=\"type\"):\n",
    "        print(f\"Loading {t} data...\")\n",
    "        display(t_df)\n",
    "        if t == \"alp\":\n",
    "            alp_data = Struct(attrs={'int_keys': True})\n",
    "            for run in t_df.index:\n",
    "                dl.reset()\n",
    "                dl.set_files(f\"run == {run}\")\n",
    "                dl.set_output(merge_files=False, columns=par_names)\n",
    "                d = dl.load()\n",
    "                alp_data[run] = d\n",
    "            alp_data.update_datatype()\n",
    "            sto.write_object(alp_data, f\"{t}_{ds}\", loaded_file, wo_mode='o')\n",
    "            data[ds][t] = alp_data\n",
    "        else:\n",
    "            dl.reset()\n",
    "            dl.set_files(f\"run in {list(ds_df.index)}\")\n",
    "            dl.set_output(merge_files=False, columns=par_names)\n",
    "            d = dl.load()\n",
    "            sto.write_object(d, f\"{t}_{ds}\", loaded_file, wo_mode='o')\n",
    "            data[ds][t] = d\n",
    "        print(f\"Saved in {loaded_file}/{t}_{ds}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    print(f\"Loading dataset {ds}\")\n",
    "    if ds not in data.keys():\n",
    "        data[ds] = {}\n",
    "    for t, t_df in ds_df.groupby(by=\"type\"):\n",
    "        data[ds][t], _ = sto.read_object(f\"{t}_{ds}\", loaded_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Runtimes and Energy Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is just to visualize what the fit is doing to the 1460 keV peak\n",
    "calibrate_energy(data[1]['alp'][525][4404]['trapEmax_ctc'].nda, ebins, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdb_df['cal_constant'] = np.nan\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    print(f\"Calculating runtime and energy for dataset {ds}\")\n",
    "    for t, t_df in ds_df.groupby(by=\"type\"):\n",
    "        if t == \"alp\":\n",
    "            for run in t_df.index:\n",
    "                if 'rt' in data[ds][t][run]:\n",
    "                    data[ds][t][run].pop('rt')\n",
    "                for file in data[ds][t][run]:\n",
    "                    cal_energies, cal_constants = calibrate_energy(data[ds][t][run][file]['trapEmax_ctc'].nda, ebins)\n",
    "                    data[ds][t][run][file]['cal_trapEmax_ctc'] = Array(nda=cal_energies)\n",
    "                    rdb_df.at[run, 'cal_constant'] = cal_constants\n",
    "                    \n",
    "                data[ds][t][run]['rt'] = get_runtime(data[ds][t][run])\n",
    "        else:\n",
    "            if 'rt' in data[ds][t]:\n",
    "                    data[ds][t].pop('rt')\n",
    "            for file in data[ds][t]:\n",
    "                cal_energies, cal_constants = calibrate_energy(data[ds][t][file]['trapEmax_ctc'].nda, ebins)\n",
    "                data[ds][t][file]['cal_trapEmax_ctc'] = Array(nda=cal_energies)\n",
    "                run = fdb.df.loc[file]['run']\n",
    "                rdb_df.at[run, 'cal_constant'] = cal_constants\n",
    "            data[ds][t]['rt'] = get_runtime(data[ds][t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: None\n",
    "\n",
    "**Human Input**: None\n",
    "\n",
    "You should probably run this section just to have the histograms available for reference later. \n",
    "The saved histograms will not be normalized by runtime, but the plots do the normalization for display purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backgrounds - Uncalibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the histograms\n",
    "bkg_uncal_spec = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    spec = None\n",
    "    for file in data[ds][\"bkg\"].keys():\n",
    "        if file == 'rt':\n",
    "            continue\n",
    "        if spec is None:\n",
    "            spec = np.histogram(data[ds][\"bkg\"][file]['trapEmax_ctc'], bins=ebins)[0]\n",
    "        else:\n",
    "            spec += np.histogram(data[ds][\"bkg\"][file]['trapEmax_ctc'], bins=ebins)[0]\n",
    "    bkg_uncal_spec[ds] = spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the histograms\n",
    "for ds in bkg_uncal_spec:\n",
    "    plt.figure()\n",
    "    pgh.plot_hist(bkg_uncal_spec[ds]/data[ds]['bkg']['rt'], bins=ebins)\n",
    "    plt.yscale('log')\n",
    "    plt.title(f\"Uncalibrated Background - Dataset {ds}\")\n",
    "    plt.xlabel(\"Energy\")\n",
    "    plt.ylabel(\"Counts/min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backgrounds - Calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the histograms\n",
    "bkg_cal_spec = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    spec = None\n",
    "    for file in data[ds][\"bkg\"].keys():\n",
    "        if file == 'rt':\n",
    "            continue\n",
    "        if spec is None:\n",
    "            spec = np.histogram(data[ds][\"bkg\"][file]['cal_trapEmax_ctc'], bins=cal_ebins)[0]\n",
    "        else:\n",
    "            spec += np.histogram(data[ds][\"bkg\"][file]['cal_trapEmax_ctc'], bins=cal_ebins)[0]\n",
    "    bkg_cal_spec[ds] = spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the histograms\n",
    "for ds in bkg_cal_spec:\n",
    "    plt.figure()\n",
    "    pgh.plot_hist(bkg_cal_spec[ds]/data[ds]['bkg']['rt'], bins=cal_ebins)\n",
    "    plt.yscale('log')\n",
    "    plt.title(f\"Calibrated Background - Dataset {ds}\")\n",
    "    plt.xlabel(\"Energy [keV]\")\n",
    "    plt.ylabel(\"Counts/min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alphas - Uncalibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the histograms\n",
    "alp_uncal_spec = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    alp_uncal_spec[ds] = {}\n",
    "    for run in data[ds][\"alp\"]:\n",
    "        spec = None\n",
    "        for file in data[ds][\"alp\"][run]:\n",
    "            if file == 'rt':\n",
    "                continue\n",
    "            if spec is None:\n",
    "                spec = np.histogram(data[ds][\"alp\"][run][file]['trapEmax_ctc'], bins=ebins)[0]\n",
    "            else:\n",
    "                spec += np.histogram(data[ds][\"alp\"][run][file]['trapEmax_ctc'], bins=ebins)[0]\n",
    "        alp_uncal_spec[ds][run] = spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the histograms\n",
    "for ds in alp_uncal_spec:\n",
    "    for run in alp_uncal_spec[ds]:\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "        rot = rdb_df.loc[run]['rotary']\n",
    "        plt.figure()\n",
    "        pgh.plot_hist(alp_uncal_spec[ds][run]/data[ds]['alp'][run]['rt'], bins=ebins)\n",
    "        plt.yscale('log')\n",
    "        plt.title(f\"Uncalibrated Alphas - Dataset {ds}, Rotary {rot} Linear {lin}\")\n",
    "        plt.xlabel(\"Energy\")\n",
    "        plt.ylabel(\"Counts/min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alphas - Calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the histograms\n",
    "alp_cal_spec = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    alp_cal_spec[ds] = {}\n",
    "    for run in data[ds][\"alp\"]:\n",
    "        spec = None\n",
    "        for file in data[ds][\"alp\"][run]:\n",
    "            if file == 'rt':\n",
    "                continue\n",
    "            if spec is None:\n",
    "                spec = np.histogram(data[ds][\"alp\"][run][file]['cal_trapEmax_ctc'], bins=cal_ebins)[0]\n",
    "            else:\n",
    "                spec += np.histogram(data[ds][\"alp\"][run][file]['cal_trapEmax_ctc'], bins=cal_ebins)[0]\n",
    "        alp_cal_spec[ds][run] = spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the histograms\n",
    "for ds in alp_cal_spec:\n",
    "    for run in alp_cal_spec[ds]:\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "        rot = rdb_df.loc[run]['rotary']\n",
    "        plt.figure()\n",
    "        pgh.plot_hist(alp_cal_spec[ds][run]/data[ds]['alp'][run]['rt'], bins=cal_ebins)\n",
    "        plt.yscale('log')\n",
    "        plt.title(f\"Calibrated Alphas - Dataset {ds}, Rotary {rot} Linear {lin}\")\n",
    "        plt.xlabel(\"Energy [keV]\")\n",
    "        plt.ylabel(\"Counts/min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alp_subbed_spec = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    alp_subbed_spec[ds] = {}\n",
    "    for run in data[ds][\"alp\"]:\n",
    "        spec = alp_cal_spec[ds][run]/data[ds]['alp'][run]['rt'] - bkg_cal_spec[ds]/data[ds]['bkg']['rt']\n",
    "        alp_subbed_spec[ds][run] = spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ds in alp_subbed_spec:\n",
    "    for run in alp_subbed_spec[ds]:\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "        rot = rdb_df.loc[run]['rotary']\n",
    "        plt.figure()\n",
    "        pgh.plot_hist(bkg_cal_spec[ds]/data[ds]['bkg']['rt'], bins=cal_ebins, label='background', color='#007bb6')\n",
    "        pgh.plot_hist(alp_cal_spec[ds][run]/data[ds]['alp'][run]['rt'], bins=cal_ebins, label='source on', color='#ff574a')\n",
    "        # pgh.plot_hist(alp_subbed_spec[ds][run], bins=cal_ebins)\n",
    "        \n",
    "        plt.yscale('log')\n",
    "        plt.title(f\"Dataset {ds}, Rotary {rot} Linear {lin}\")\n",
    "        plt.xlabel(\"Energy [keV]\")\n",
    "        plt.ylabel(\"Counts/min\")\n",
    "        plt.xlim(50, 70)\n",
    "        plt.ylim(0.08, 0.2)\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector Characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: \"Energy Histograms: Backgrounds - Uncalibrated\"\n",
    "\n",
    "**Human Input**: `uncal_guesses` locations of uncalibrated peaks\n",
    "\n",
    "This will compare the uncalibrated background spectra of multiple datasets and find the peaks relative to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uncal_guesses = {\n",
    "    0: [1100, 1320, 3200, 3850,5700],\n",
    "    1: [1250, 1500, 3550, 4300, 6375]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uncal_peak_locs = {}\n",
    "for ds in uncal_guesses:\n",
    "    uncal_peak_locs[ds] = []\n",
    "    for i in range(len(uncal_guesses[ds])):\n",
    "        popt, pcov, _ = fit_peak(bkg_uncal_spec[ds], ebins, uncal_guesses[ds][i], plot=True, )\n",
    "        uncal_peak_locs[ds].append(popt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histograms\n",
    "for ds in bkg_uncal_spec:\n",
    "    plt.figure()\n",
    "    pgh.plot_hist(bkg_uncal_spec[ds]/data[ds]['bkg']['rt'], bins=ebins)\n",
    "    plt.yscale('log')\n",
    "    plt.title(f\"Uncalibrated Background - Dataset {ds}\")\n",
    "    plt.xlabel(\"Energy\")\n",
    "    plt.ylabel(\"Counts/min\")\n",
    "    for p in uncal_peak_locs[ds]:\n",
    "        plt.axvline(p, linestyle='dashed', color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = list(uncal_peak_locs.keys())[0]\n",
    "\n",
    "for ds in uncal_peak_locs:\n",
    "    print(f\"Peak location ratio, dataset {ds} : dataset {base}  \", np.average(np.array(uncal_peak_locs[ds]) / np.array(uncal_peak_locs[base]) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearity and Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: \"Energy Histograms: Backgrounds - Calibrated\"\n",
    "\n",
    "**Human Input**: None\n",
    "\n",
    "This fits a bunch of calibrated, expected peaks to compare to where we expect them to be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "known_peaks = {\n",
    "    'beta+': 511, \n",
    "    '228Ac': 911.2, \n",
    "    '40K': 1460.8, \n",
    "    '214Bi': 1764.5, \n",
    "    '208Tl': 2614.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cal_peak_locs = {}\n",
    "cal_peak_widths = {}\n",
    "for ds in bkg_cal_spec:\n",
    "    cal_peak_locs[ds] = []\n",
    "    cal_peak_widths[ds] = []\n",
    "    for peak in known_peaks.values():\n",
    "        popt, pcov, _ = fit_peak(bkg_cal_spec[ds], cal_ebins, peak, plot=True)\n",
    "        cal_peak_locs[ds].append(popt[1])\n",
    "        cal_peak_widths[ds].append(popt[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "known_peak_vals = np.array(list(known_peaks.values()))\n",
    "plt.figure()\n",
    "for ds in cal_peak_locs:\n",
    "    plt.scatter(known_peak_vals, np.array(cal_peak_locs[ds]) - known_peak_vals, label=f\"dataset {ds}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Known Peak Energy [keV]\")\n",
    "plt.ylabel(\"Energy Residual [keV]\")\n",
    "plt.title(\"Energy Linearity\")\n",
    "plt.axhline(0, color='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for ds in cal_peak_locs:\n",
    "    plt.scatter(known_peak_vals, np.array(cal_peak_widths[ds]), label=f\"dataset {ds}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Known Peak Energy [keV]\")\n",
    "plt.ylabel(\"Peak Width [keV]\")\n",
    "plt.title(\"Energy Resolution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for ds in cal_peak_locs:\n",
    "    plt.scatter(known_peak_vals, np.array(cal_peak_widths[ds])*2.355, label=f\"dataset {ds}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Known Peak Energy [keV]\")\n",
    "plt.ylabel(\"FWHM [keV]\")\n",
    "plt.title(\"Energy Resolution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter vs. Time Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: None\n",
    "\n",
    "**Human Input**: None\n",
    "\n",
    "Plot 2D 'Parameter vs. Time' plots for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[1][\"alp\"][525]['rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_partime_hist(par):\n",
    "    \"\"\"\n",
    "    par: str, name of parameter in Table\n",
    "    \"\"\"\n",
    "    par_time_hist = {}\n",
    "    for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "        par_time_hist[ds] = {}\n",
    "        total_rt = sum(data[ds][\"alp\"][run]['rt']*1e9 for run in data[ds][\"alp\"])\n",
    "        \n",
    "        hist = None\n",
    "        time_bins = np.linspace(0, total_rt, 1500)\n",
    "        if par == \"trapEmax_ctc\":\n",
    "            k40_peak = ebins[np.argmax(bkg_uncal_spec[ds][3000:]) + 3000]\n",
    "            par_bins = np.linspace(k40_peak - 100, k40_peak + 100, 300)\n",
    "        else:\n",
    "            par_bins = bins[par]\n",
    "        \n",
    "        last_time = 0\n",
    "        \n",
    "        # Make each alpha histogram\n",
    "        for run in data[ds][\"alp\"]:\n",
    "            for i, file in enumerate(data[ds][\"alp\"][run]):\n",
    "                if file == 'rt':\n",
    "                    continue\n",
    "                \n",
    "                if par == \"tp_20\":\n",
    "                    par_vals = data[ds][\"alp\"][run][file][par].nda - data[ds][\"alp\"][run][file][\"tp_0\"].nda\n",
    "                elif par == \"tp_90\":\n",
    "                    par_vals = data[ds][\"alp\"][run][file][par].nda - data[ds][\"alp\"][run][file][\"tp_10\"].nda\n",
    "                else:\n",
    "                    par_vals = data[ds][\"alp\"][run][file][par]\n",
    "                \n",
    "                time = data[ds][\"alp\"][run][file][\"timestamp\"].nda*10 + last_time\n",
    "                last_time = time[-1]\n",
    "                \n",
    "                if hist is None:\n",
    "                    hist = np.histogram2d(time, par_vals, bins=(time_bins, par_bins))[0]\n",
    "                else:\n",
    "                    hist += np.histogram2d(time, par_vals, bins=(time_bins, par_bins))[0]\n",
    "        par_time_hist[ds]['hist'] = hist\n",
    "        par_time_hist[ds]['bins'] = time_bins, par_bins\n",
    "            \n",
    "    return par_time_hist\n",
    "\n",
    "    \n",
    "def plot_partime(par, par_time_hist, save=False, runs=None, cuts=None):\n",
    "    \"\"\"\n",
    "    par: str, name of parameter in Table\n",
    "    save: save figures in plots folder\n",
    "    \"\"\"\n",
    "    cmap = copy.copy(mpl.colormaps['viridis'])\n",
    "    \n",
    "    for ds in par_time_hist:\n",
    "        if par == 'dcr':\n",
    "            label = \"DCR [arb]\"\n",
    "        elif par == 'cal_ToE':\n",
    "            label = \"T/E (calibrated) [arb]\"\n",
    "        elif par == 'ToE':\n",
    "            label = \"T/E [arb]\"\n",
    "        elif par == 'tp_20':\n",
    "            label = \"tp20-tp0 [ns]\"\n",
    "        else:\n",
    "            label = par\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(f\"{par} vs Time, Dataset {ds}\")\n",
    "        plt.xlabel(\"Time [ns]\")\n",
    "        plt.ylabel(f\"{label}\")\n",
    "\n",
    "        # zero_percentile = percentileofscore(np.ndarray.flatten(par_energy_hist[ds][run]), 0)\n",
    "        plt.pcolor(par_time_hist[ds]['bins'][0], par_time_hist[ds]['bins'][1], par_time_hist[ds]['hist'].T, \n",
    "               cmap=cmap, norm=colors.LogNorm())\n",
    "        # plt.colorbar()\n",
    "\n",
    "        if cuts is not None:\n",
    "            for cut in cuts:\n",
    "                plt.axhline(cut, color='red')\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(f\"plots/{par}_vs_time_ds{ds}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncalibrated Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_time_hist = make_partime_hist(\"trapEmax_ctc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_partime(\"trapEmax_ctc\", energy_time_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## T/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toe_time_hist = make_partime_hist(\"ToE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_partime(\"ToE\", toe_time_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated T/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "caltoe_time_hist = make_partime_hist(\"cal_ToE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_partime(\"cal_ToE\", caltoe_time_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter vs. Energy Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: None\n",
    "\n",
    "**Human Input**: None\n",
    "\n",
    "Plot 2D background subtracted 'Parameter vs. Energy' plots for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_parE_hist(par):\n",
    "    \"\"\"\n",
    "    par: str, name of parameter in Table\n",
    "    \"\"\"\n",
    "    par_energy_hist = {}\n",
    "    for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "        par_energy_hist[ds] = {}\n",
    "        \n",
    "        # Make the background histogram\n",
    "        hist = None\n",
    "        for file in data[ds][\"bkg\"]:\n",
    "            if file == 'rt':\n",
    "                continue\n",
    "\n",
    "            if par == \"tp_20\":\n",
    "                par_vals = data[ds][\"bkg\"][file][par].nda - data[ds][\"bkg\"][file][\"tp_0\"].nda\n",
    "            elif par == \"tp_90\":\n",
    "                par_vals = data[ds][\"bkg\"][file][par].nda - data[ds][\"bkg\"][file][\"tp_10\"].nda\n",
    "            else:\n",
    "                par_vals = data[ds][\"bkg\"][file][par]\n",
    "\n",
    "            if hist is None:\n",
    "                hist = np.histogram2d(data[ds][\"bkg\"][file]['cal_trapEmax_ctc'], par_vals, bins=(cal_ebins, bins[par]))[0]\n",
    "            else:\n",
    "                hist += np.histogram2d(data[ds][\"bkg\"][file]['cal_trapEmax_ctc'], par_vals, bins=(cal_ebins, bins[par]))[0]\n",
    "            hist /= data[ds][\"bkg\"][\"rt\"]\n",
    "            par_energy_hist[ds][\"bkg\"] = hist\n",
    "        \n",
    "        # Make each alpha histogram and perform background subtraction\n",
    "        for run in data[ds][\"alp\"]:\n",
    "            hist = None\n",
    "            for file in data[ds][\"alp\"][run]:\n",
    "                if file == 'rt':\n",
    "                    continue\n",
    "                \n",
    "                if par == \"tp_20\":\n",
    "                    par_vals = data[ds][\"alp\"][run][file][par].nda - data[ds][\"alp\"][run][file][\"tp_0\"].nda\n",
    "                elif par == \"tp_90\":\n",
    "                    par_vals = data[ds][\"alp\"][run][file][par].nda - data[ds][\"alp\"][run][file][\"tp_10\"].nda\n",
    "                else:\n",
    "                    par_vals = data[ds][\"alp\"][run][file][par]\n",
    "                \n",
    "                if hist is None:\n",
    "                    hist = np.histogram2d(data[ds][\"alp\"][run][file]['cal_trapEmax_ctc'], par_vals, bins=(cal_ebins, bins[par]))[0]\n",
    "                else:\n",
    "                    hist += np.histogram2d(data[ds][\"alp\"][run][file]['cal_trapEmax_ctc'], par_vals, bins=(cal_ebins, bins[par]))[0]\n",
    "            hist /= data[ds][\"alp\"][run][\"rt\"]\n",
    "            hist -= par_energy_hist[ds][\"bkg\"]\n",
    "            par_energy_hist[ds][run] = hist\n",
    "            \n",
    "    return par_energy_hist\n",
    "\n",
    "    \n",
    "def plot_parE(par, par_energy_hist, save=False, runs=None, cuts=None):\n",
    "    \"\"\"\n",
    "    par: str, name of parameter in Table\n",
    "    save: save figures in plots folder\n",
    "    \"\"\"\n",
    "    cmap = copy.copy(mpl.colormaps['coolwarm'])\n",
    "    \n",
    "    for ds in par_energy_hist:\n",
    "        for run in par_energy_hist[ds]: \n",
    "            if run == \"bkg\":\n",
    "                continue\n",
    "                \n",
    "            if runs is not None:\n",
    "                if run not in runs:\n",
    "                    continue\n",
    "            rot = rdb_df.loc[run]['rotary']\n",
    "            lin = rdb_df.loc[run]['linear']\n",
    "            src = rdb_df.loc[run]['source']\n",
    "            \n",
    "            if par == 'dcr':\n",
    "                label = \"DCR [arb]\"\n",
    "            elif par == 'cal_ToE':\n",
    "                label = \"T/E (calibrated) [arb]\"\n",
    "            elif par == 'ToE':\n",
    "                label = \"T/E [arb]\"\n",
    "            elif par == 'tp_20':\n",
    "                label = \"tp20-tp0 [ns]\"\n",
    "            else:\n",
    "                label = par\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.title(f\"{par} vs Energy, Dataset {ds} Rotary {rot}, Linear {lin}\")\n",
    "            plt.xlabel(\"Energy [keV]\")\n",
    "            plt.ylabel(f\"{label}\")\n",
    "            \n",
    "            # zero_percentile = percentileofscore(np.ndarray.flatten(par_energy_hist[ds][run]), 0)\n",
    "            lim = -1 * np.min(par_energy_hist[ds][run])/10\n",
    "            plt.pcolor(cal_ebins, bins[par], par_energy_hist[ds][run].T, \n",
    "                   cmap=cmap, norm=colors.SymLogNorm(linthresh=0.00001, vmin=-1*lim, vmax=lim))\n",
    "            plt.colorbar()\n",
    "            \n",
    "            if cuts is not None:\n",
    "                for cut in cuts:\n",
    "                    plt.axhline(cut, color='green')\n",
    "            \n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            if save:\n",
    "                plt.savefig(f\"plots/{par}_rot{rot}_linear{lin}_source{src}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcr_energy_hist = make_parE_hist(\"dcr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_parE(\"dcr\", dcr_energy_hist) #plot only the runs in `runs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## T/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toe_energy_hist = make_parE_hist(\"ToE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_parE(\"ToE\", toe_energy_hist) #plot every alpha run\n",
    "plot_parE(\"ToE\", toe_energy_hist) #plot only the runs in `runs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calibrated T/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cal_toe_energy_hist = make_parE_hist(\"cal_ToE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_parE(\"cal_ToE\", cal_toe_energy_hist) #plot every alpha run\n",
    "# plot_parE(\"cal_ToE\", cal_toe_energy_hist, runs=[527, 526, 525, 531, 532, 534]) #plot only the runs in `runs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_parE_gamma(\"cal_ToE\", cal_toe_energy_hist) #plot every alpha run\n",
    "# plot_parE(\"cal_ToE\", cal_toe_energy_hist, runs=[527, 526, 525, 531, 532, 534]) #plot only the runs in `runs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## tp20 - tp0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tp20_energy_hist = make_parE_hist(\"tp_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_parE(\"tp_20\", tp20_energy_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter vs. Energy - wrt Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_parE_hist_sig(par):\n",
    "    \"\"\"\n",
    "    par: str, name of parameter in Table\n",
    "    \"\"\"\n",
    "    par_energy_hist = {}\n",
    "    for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "        par_energy_hist[ds] = {}\n",
    "        \n",
    "        # Make the background histogram\n",
    "        hist = None\n",
    "        for file in data[ds][\"bkg\"]:\n",
    "            if file == 'rt':\n",
    "                continue\n",
    "\n",
    "            if par == \"tp_20\":\n",
    "                par_vals = data[ds][\"bkg\"][file][par].nda - data[ds][\"bkg\"][file][\"tp_0\"].nda\n",
    "            elif par == \"tp_90\":\n",
    "                par_vals = data[ds][\"bkg\"][file][par].nda - data[ds][\"bkg\"][file][\"tp_10\"].nda\n",
    "            else:\n",
    "                par_vals = data[ds][\"bkg\"][file][par]\n",
    "\n",
    "            if hist is None:\n",
    "                hist = np.histogram2d(data[ds][\"bkg\"][file]['cal_trapEmax_ctc'], par_vals, bins=(cal_ebins, bins[par]))[0]\n",
    "            else:\n",
    "                hist += np.histogram2d(data[ds][\"bkg\"][file]['cal_trapEmax_ctc'], par_vals, bins=(cal_ebins, bins[par]))[0]\n",
    "            hist /= data[ds][\"bkg\"][\"rt\"]\n",
    "            par_energy_hist[ds][\"bkg\"] = hist\n",
    "        \n",
    "        # Make each alpha histogram and perform background subtraction\n",
    "        for run in data[ds][\"alp\"]:\n",
    "            hist = None\n",
    "            for file in data[ds][\"alp\"][run]:\n",
    "                if file == 'rt':\n",
    "                    continue\n",
    "                \n",
    "                if par == \"tp_20\":\n",
    "                    par_vals = data[ds][\"alp\"][run][file][par].nda - data[ds][\"alp\"][run][file][\"tp_0\"].nda\n",
    "                elif par == \"tp_90\":\n",
    "                    par_vals = data[ds][\"alp\"][run][file][par].nda - data[ds][\"alp\"][run][file][\"tp_10\"].nda\n",
    "                else:\n",
    "                    par_vals = data[ds][\"alp\"][run][file][par]\n",
    "                \n",
    "                if hist is None:\n",
    "                    hist = np.histogram2d(data[ds][\"alp\"][run][file]['cal_trapEmax_ctc'], par_vals, bins=(cal_ebins, bins[par]))[0]\n",
    "                else:\n",
    "                    hist += np.histogram2d(data[ds][\"alp\"][run][file]['cal_trapEmax_ctc'], par_vals, bins=(cal_ebins, bins[par]))[0]\n",
    "            hist_unc = np.sqrt(hist/(data[ds][\"alp\"][run][\"rt\"]**2) + par_energy_hist[ds][\"bkg\"]/(data[ds][\"bkg\"][\"rt\"]**2) )        \n",
    "            \n",
    "            hist /= data[ds][\"alp\"][run][\"rt\"]\n",
    "            hist -= par_energy_hist[ds][\"bkg\"]\n",
    "            \n",
    "            par_energy_hist[ds][run] = hist/hist_unc\n",
    "            \n",
    "    return par_energy_hist\n",
    "    \n",
    "def plot_parE(par, par_energy_hist, save=False, runs=None, cuts=None):\n",
    "    \"\"\"\n",
    "    par: str, name of parameter in Table\n",
    "    save: save figures in plots folder\n",
    "    \"\"\"\n",
    "    cmap = copy.copy(mpl.colormaps['coolwarm'])\n",
    "    # cmap = copy.copy(mpl.colormaps['viridis'])\n",
    "    # cmap.set_bad('#440154')\n",
    "    # cmap.set_under('#440154')\n",
    "    \n",
    "    for ds in par_energy_hist:\n",
    "        for run in par_energy_hist[ds]: \n",
    "            if run == \"bkg\":\n",
    "                continue\n",
    "                \n",
    "            if runs is not None:\n",
    "                if run not in runs:\n",
    "                    continue\n",
    "            rot = rdb_df.loc[run]['rotary']\n",
    "            lin = rdb_df.loc[run]['linear']\n",
    "            src = rdb_df.loc[run]['source']\n",
    "            \n",
    "            if par == 'dcr':\n",
    "                label = \"DCR [arb]\"\n",
    "            elif par == 'cal_ToE':\n",
    "                label = \"T/E (calibrated) [arb]\"\n",
    "            elif par == 'ToE':\n",
    "                label = \"T/E [arb]\"\n",
    "            elif par == 'tp_20':\n",
    "                label = \"tp20-tp0 [ns]\"\n",
    "            else:\n",
    "                label = par\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.title(f\"{par} vs Energy, Dataset {ds} Rotary {rot}, Linear {lin}\")\n",
    "            plt.xlabel(\"Energy [keV]\")\n",
    "            plt.ylabel(f\"{label}\")\n",
    "            \n",
    "            # zero_percentile = percentileofscore(np.ndarray.flatten(par_energy_hist[ds][run]), 0)\n",
    "            # lim = -1 * np.min(par_energy_hist[ds][run])/10\n",
    "            plt.pcolor(cal_ebins, bins[par], par_energy_hist[ds][run].T, #cmap=cmap, norm=colors.LogNorm())\n",
    "                   cmap=cmap, norm=colors.SymLogNorm(linthresh=0.00001, vmin=-1e1, vmax=1e1))\n",
    "            cbar = plt.colorbar()\n",
    "            # plt.xlim(50, 70)\n",
    "            # plt.ylim(-1, 1)\n",
    "            \n",
    "            cbar.ax.set_ylabel(f\"Counts/min/sigma\")\n",
    "            \n",
    "            if cuts is not None:\n",
    "                for cut in cuts:\n",
    "                    plt.axhline(cut, color='green')\n",
    "            \n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            if save:\n",
    "                plt.savefig(f\"plots/{par}_ds{ds}_rot{rot}_linear{lin}_source{src}.png\")\n",
    "                \n",
    "def plot_parE_gamma(par, par_energy_hist, save=False, runs=None, cuts=None):\n",
    "    \"\"\"\n",
    "    par: str, name of parameter in Table\n",
    "    save: save figures in plots folder\n",
    "    \"\"\"\n",
    "    # cmap = copy.copy(mpl.colormaps['coolwarm'])\n",
    "    cmap = copy.copy(mpl.colormaps['viridis'])\n",
    "    cmap.set_bad('#440154')\n",
    "    cmap.set_under('#440154')\n",
    "    \n",
    "    for ds in par_energy_hist:\n",
    "        for run in par_energy_hist[ds]: \n",
    "            if run == \"bkg\":\n",
    "                continue\n",
    "                \n",
    "            if runs is not None:\n",
    "                if run not in runs:\n",
    "                    continue\n",
    "            rot = rdb_df.loc[run]['rotary']\n",
    "            lin = rdb_df.loc[run]['linear']\n",
    "            src = rdb_df.loc[run]['source']\n",
    "            \n",
    "            if par == 'dcr':\n",
    "                label = \"DCR [arb]\"\n",
    "            elif par == 'cal_ToE':\n",
    "                label = \"T/E (calibrated) [arb]\"\n",
    "            elif par == 'ToE':\n",
    "                label = \"T/E [arb]\"\n",
    "            elif par == 'tp_20':\n",
    "                label = \"tp20-tp0 [ns]\"\n",
    "            else:\n",
    "                label = par\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.title(f\"{par} vs Energy, Dataset {ds} Rotary {rot}, Linear {lin}\")\n",
    "            plt.xlabel(\"Energy [keV]\")\n",
    "            plt.ylabel(f\"{label}\")\n",
    "            \n",
    "            # zero_percentile = percentileofscore(np.ndarray.flatten(par_energy_hist[ds][run]), 0)\n",
    "            # lim = -1 * np.min(par_energy_hist[ds][run])/10\n",
    "            plt.pcolor(cal_ebins, bins[par], par_energy_hist[ds][run].T, cmap=cmap, norm=colors.LogNorm())\n",
    "                   # cmap=cmap, norm=colors.SymLogNorm(linthresh=0.00001))\n",
    "            cbar = plt.colorbar()\n",
    "            # plt.xlim(50, 70)\n",
    "            # plt.ylim(-1, 1)\n",
    "            \n",
    "            cbar.ax.set_ylabel(f\"Counts/min/sigma\")\n",
    "            \n",
    "            if cuts is not None:\n",
    "                for cut in cuts:\n",
    "                    plt.axhline(cut, color='green')\n",
    "            plt.xlim(50, 70)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            if save:\n",
    "                plt.savefig(f\"plots/{par}_ds{ds}_rot{rot}_linear{lin}_source{src}_gamma.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toe_energy_sighist = make_parE_hist_sig(\"ToE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_parE(\"ToE\", toe_energy_sighist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated T/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cal_toe_energy_sighist = make_parE_hist_sig(\"cal_ToE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_parE(\"cal_ToE\", cal_toe_energy_sighist, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_parE_gamma(\"cal_ToE\", cal_toe_energy_sighist, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcr_energy_sighist = make_parE_hist_sig(\"dcr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_parE(\"dcr\", dcr_energy_sighist, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: Background and alpha, calibrated energy histograms\n",
    "\n",
    "**Human Input**: low energy threshold for alphas\n",
    "\n",
    "Number of events in alpha run - number of events in background run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "low_e_thresh = 200 # keV\n",
    "thresh_idx = np.argmin(np.abs(cal_ebins - low_e_thresh))\n",
    "\n",
    "alpha_rates = {}\n",
    "for ds in alp_cal_spec:\n",
    "    alpha_rates[ds] = {}\n",
    "    for run in alp_cal_spec[ds]:\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "        rot = rdb_df.loc[run]['rotary']\n",
    "        \n",
    "        if rot not in alpha_rates[ds]:\n",
    "            alpha_rates[ds][rot] = {}        \n",
    "        \n",
    "        alpha_rates[ds][rot][lin] = np.sum(alp_cal_spec[ds][run][thresh_idx:]/data[ds]['alp'][run]['rt'] - bkg_cal_spec[ds][thresh_idx:]/data[ds]['bkg']['rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rotary_colors = {\n",
    "    0: mpl.cm.get_cmap('Blues'),\n",
    "    180: mpl.cm.get_cmap('Greens'),\n",
    "    145: mpl.cm.get_cmap('Reds')\n",
    "}\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Alpha Rates\")\n",
    "plt.xlabel(\"Linear Position\")\n",
    "plt.ylabel(\"Counts\")\n",
    "for ds in alpha_rates:\n",
    "    for rot in alpha_rates[ds]:\n",
    "        plt.scatter(alpha_rates[ds][rot].keys(), alpha_rates[ds][rot].values(), label=f'Dataset {ds}, Rotary {rot}', color=rotary_colors[rot](1-ds*0.4))\n",
    "    plt.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drifting A/E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: None\n",
    "\n",
    "**Human Input**: None\n",
    "\n",
    "Looks at A/E distributions on a run-by-run basis, looking for correlations with linear position. Also looks for drifting within a run by looking at scatter plots of timestamp vs. A/E and cycle-by-cycle distributions of A/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up color maps\n",
    "lin_cmap = mpl.cm.get_cmap('rainbow')\n",
    "lin_colors = {}\n",
    "min_lin = rdb_df['linear'].min()\n",
    "max_lin = rdb_df['linear'].max()\n",
    "\n",
    "for lin in rdb_df['linear'].unique():\n",
    "    frac = (lin - min_lin) / (max_lin - min_lin)\n",
    "    lin_colors[lin] = lin_cmap(frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make A/E histograms by run\n",
    "AoE_hists = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    AoE_hists[ds] = {}\n",
    "    \n",
    "    for run in ds_df.index:\n",
    "        files = fdb.df.query(f\"run == {run}\").index\n",
    "        t = ds_df.loc[run]['type']\n",
    "        hist = None\n",
    "        \n",
    "        for file in files:\n",
    "            if t == 'alp':\n",
    "                d = data[ds][\"alp\"][run][file]['AoE']\n",
    "            else:\n",
    "                d = data[ds][t][file]['AoE']\n",
    "                \n",
    "            if hist is None:\n",
    "                hist = np.histogram(d, bins=aoe_bins)[0]\n",
    "            else:\n",
    "                hist += np.histogram(d, bins=aoe_bins)[0]\n",
    "        AoE_hists[ds][run] = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ds in AoE_hists:\n",
    "    plt.figure()\n",
    "    plt.title(f\"Dataset {ds} A/E\")\n",
    "    plt.xlabel(\"A/E\")\n",
    "    plt.ylabel(\"Counts (normalized) \")\n",
    "    for run in rdb_df.query(f' dataset == {ds}').index:\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "        pgh.plot_hist(AoE_hists[ds][run]/np.max(AoE_hists[ds][run]), bins=aoe_bins, color=lin_colors[lin], label=f'run {run}')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make A/E histograms by run\n",
    "AoE_time_hists = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    hist = None\n",
    "    time_bins = np.linspace(0, len(ds_df)*1e11, 5000)\n",
    "    \n",
    "    files = None\n",
    "    types = None\n",
    "    \n",
    "    for run in sort(ds_df.index):\n",
    "        run_files = fdb.df.query(f\"run == {run}\").index\n",
    "        \n",
    "        \n",
    "        if files is None:\n",
    "            files = run_files\n",
    "            types = ds_df.loc[run]['type']*len(run_files)\n",
    "        else:\n",
    "            files = np.concatenate(files, run_files)\n",
    "            types = np.concatenate(types, ds_df.loc[run]['type']*run_files)\n",
    "        \n",
    "    # THIS IS NOT DONE - add startTime to filedb I think is the best way to do this. This is a lot of work for something not very good. \n",
    "    min_file = np.min(files)\n",
    "\n",
    "    for file, t in files, types:\n",
    "        if t == 'alp':\n",
    "            aoe_d = data[ds][\"alp\"][run][file]['AoE']\n",
    "            ts_d = data[ds][\"alp\"][run][file]['timestamp']\n",
    "        else:\n",
    "            aoe_d = data[ds][t][file]['AoE']\n",
    "            ts_d = data[ds][t][file]['timestamp']\n",
    "\n",
    "        ts_d += (file-min_file)*1e11\n",
    "\n",
    "        if hist is None:\n",
    "            hist = np.histogram2d(ts_d, aoe_d, bins=(aoe_bins, time_bins))[0]\n",
    "        else:\n",
    "            hist += np.histogram2d(ts_d, aoe_d, bins=(aoe_bins, time_bins))[0]\n",
    "    AoE_time_hists[ds] = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[0][\"alp\"][496][3952]['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drifting T/E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: None\n",
    "\n",
    "**Human Input**: None\n",
    "\n",
    "Looks at T/E distributions on a run-by-run basis, looking for correlations with linear position. Also looks for drifting within a run by looking at scatter plots of timestamp vs. T/E and cycle-by-cycle distributions of T/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up color maps\n",
    "lin_cmap = mpl.cm.get_cmap('rainbow')\n",
    "lin_colors = {}\n",
    "min_lin = rdb_df['linear'].min()\n",
    "max_lin = rdb_df['linear'].max()\n",
    "\n",
    "for lin in rdb_df['linear'].unique():\n",
    "    frac = (lin - min_lin) / (max_lin - min_lin)\n",
    "    lin_colors[lin] = lin_cmap(frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make T/E histograms by run\n",
    "ToE_hists = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    ToE_hists[ds] = {}\n",
    "    \n",
    "    for run in ds_df.index:\n",
    "        files = fdb.df.query(f\"run == {run}\").index\n",
    "        t = ds_df.loc[run]['type']\n",
    "        hist = None\n",
    "        \n",
    "        for file in files:\n",
    "            if t == 'alp':\n",
    "                d = data[ds][\"alp\"][run][file]['ToE']\n",
    "            else:\n",
    "                d = data[ds][t][file]['ToE']\n",
    "                \n",
    "            if hist is None:\n",
    "                hist = np.histogram(d, bins=toe_bins)[0]\n",
    "            else:\n",
    "                hist += np.histogram(d, bins=toe_bins)[0]\n",
    "        ToE_hists[ds][run] = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot background T/E, color-coding with linear position\n",
    "for ds in ToE_hists:\n",
    "    plt.figure()\n",
    "    plt.title(f\"Dataset {ds} Background T/E\")\n",
    "    plt.xlabel(\"T/E\")\n",
    "    plt.ylabel(\"Counts (normalized) \")\n",
    "    for run in rdb_df.query(f' dataset == {ds} and type == \"bkg\" ').index:\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "        pgh.plot_hist(ToE_hists[ds][run]/np.max(ToE_hists[ds][run]), bins=toe_bins, color=lin_colors[lin], label=f'linear {lin}')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot T/E for the same linear position if we have multiple runs at that position\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    for lin, lin_df in ds_df.groupby(by=\"linear\"):\n",
    "        if len(lin_df) > 1: \n",
    "            plt.figure()\n",
    "            plt.title(f\"Dataset {ds} - T/E Linear {lin}\")\n",
    "            plt.xlabel(\"T/E\")\n",
    "            plt.ylabel(\"Counts (normalized)\")\n",
    "            for run in lin_df.index:\n",
    "                pgh.plot_hist(ToE_hists[ds][run]/np.max(ToE_hists[ds][run]), bins=toe_bins, label=f'run {run}')\n",
    "            plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runs = [525, 526, 527, 528, 529, 530, 531, 532, 534]\n",
    "#[503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514]\n",
    "ds = 1\n",
    "cmap = mpl.cm.get_cmap('rainbow')\n",
    "\n",
    "for run in runs:\n",
    "    files = fdb.df.query(f\"run == {run}\").index\n",
    "    t = rdb_df.loc[run]['type']\n",
    "    ts = 0\n",
    "\n",
    "    rot = rdb_df.loc[run]['rotary']\n",
    "    lin = rdb_df.loc[run]['linear']\n",
    "    src = rdb_df.loc[run]['source']\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        if t == 'alp':\n",
    "            plt.scatter(data[ds][t][run][file]['ToE'], ts + data[ds][t][run][file]['timestamp'].nda, marker=\".\", alpha=0.006, s=1, color=cmap(i/len(files)))\n",
    "            plt.ylabel(\"Timestamp\")\n",
    "            plt.xlabel(\"T/E\")\n",
    "            ts += np.max(data[ds][t][run][file]['timestamp'].nda)\n",
    "        else:\n",
    "            plt.scatter(data[ds][t][file]['ToE'], ts + data[ds][t][file]['timestamp'].nda, marker=\".\", alpha=0.006, s=1, color=cmap(i/len(files)))\n",
    "            plt.ylabel(\"Timestamp\")\n",
    "            plt.xlabel(\"T/E\")\n",
    "            ts += np.max(data[ds][t][file]['timestamp'].nda)\n",
    "\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.title(f\"T/E over time - {t.title()} Linear {lin}\")\n",
    "\n",
    "    plt.figure()\n",
    "    pgh.plot_hist(ToE_hists[ds][run]/np.max(ToE_hists[ds][run]), bins=toe_bins, label=f'linear {lin}')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('T/E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = mpl.cm.get_cmap('rainbow')\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel('Normalized Count')\n",
    "plt.xlabel('T/E')\n",
    "\n",
    "for run in runs:\n",
    "    files = fdb.df.query(f\"run == {run}\").index\n",
    "    t = rdb_df.loc[run]['type']\n",
    "    ts = 0\n",
    "\n",
    "    rot = rdb_df.loc[run]['rotary']\n",
    "    lin = rdb_df.loc[run]['linear']\n",
    "    src = rdb_df.loc[run]['source']\n",
    "\n",
    "    pgh.plot_hist(ToE_hists[ds][run]/np.max(ToE_hists[ds][run]), bins=toe_bins, label=f'linear {lin}', color=cmap((run-runs[0])/len(runs)))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    files = fdb.df.query(f\"run == {run}\").index\n",
    "    t = rdb_df.loc[run]['type']\n",
    "    ts = 0\n",
    "\n",
    "    cmap = mpl.cm.get_cmap('rainbow')\n",
    "\n",
    "    ds = rdb_df.loc[run]['dataset']\n",
    "    rot = rdb_df.loc[run]['rotary']\n",
    "    lin = rdb_df.loc[run]['linear']\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for file in files[:-1]:\n",
    "        if t == 'alp':\n",
    "            hist = np.histogram(data[ds][t][run][file]['ToE'], bins=toe_bins)[0]\n",
    "            pgh.plot_hist(hist/np.max(hist), bins=toe_bins, label=f'cycle {fdb.df.loc[file][\"cycle\"]}', color=cmap(list(files).index(file)/len(files)))\n",
    "        else:\n",
    "            hist = np.histogram(data[ds][t][file]['ToE'], bins=toe_bins)[0]\n",
    "            pgh.plot_hist(hist/np.max(hist), bins=toe_bins, label=f'cycle {fdb.df.loc[file][\"cycle\"]}', color=cmap(list(files).index(file)/len(files)))\n",
    "\n",
    "    #plt.xlim(0.2, 0.5)\n",
    "    #plt.ylim(0, 0.15)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('T/E')\n",
    "    plt.title(f\"Dataset {ds} - Rotary {rot} Linear {lin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calibrating T/E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: Drifting T/E\n",
    "\n",
    "**Human Input**: None\n",
    "\n",
    "Shift T/E distributions for each cycle to align the peaks at zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdb_df['toe_mode'] = np.nan\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    print(f\"Calibrating T/E for dataset {ds}\")\n",
    "    for t, t_df in ds_df.groupby(by=\"type\"):\n",
    "        if t == \"alp\":\n",
    "            for run in t_df.index:\n",
    "                for file in data[ds][t][run]:\n",
    "                    if file == 'rt':\n",
    "                        continue\n",
    "                    cal_toe, toe_modes = calibrate_toe(data[ds][t][run][file]['ToE'].nda, toe_bins)\n",
    "                    data[ds][t][run][file]['cal_ToE'] = Array(nda=cal_toe)\n",
    "                    rdb_df.at[run, 'toe_mode'] = toe_modes\n",
    "                    \n",
    "        else:\n",
    "            for file in data[ds][t]:\n",
    "                if file == 'rt':\n",
    "                    continue\n",
    "                cal_toe, toe_modes = calibrate_toe(data[ds][t][file]['ToE'].nda, toe_bins)\n",
    "                data[ds][t][file]['cal_ToE'] = Array(nda=cal_toe)\n",
    "                run = fdb.df.loc[file]['run']\n",
    "                rdb_df.at[run, 'toe_mode'] = toe_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make T/E histograms by run\n",
    "cal_ToE_hists = {}\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    cal_ToE_hists[ds] = {}\n",
    "    \n",
    "    for run in ds_df.index:\n",
    "        files = fdb.df.query(f\"run == {run}\").index\n",
    "        t = ds_df.loc[run]['type']\n",
    "        hist = None\n",
    "        \n",
    "        for file in files:\n",
    "            if t == 'alp':\n",
    "                d = data[ds][\"alp\"][run][file]['cal_ToE']\n",
    "            else:\n",
    "                d = data[ds][t][file]['cal_ToE']\n",
    "                \n",
    "            if hist is None:\n",
    "                hist = np.histogram(d, bins=cal_toe_bins)[0]\n",
    "            else:\n",
    "                hist += np.histogram(d, bins=cal_toe_bins)[0]\n",
    "        cal_ToE_hists[ds][run] = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# runs = [508, 509, 510, 511, 512, 513, 514]\n",
    "runs = [525, 526, 527, 528, 529, 530, 531, 532, 534]\n",
    "ds = 1\n",
    "cmap = mpl.cm.get_cmap('rainbow')\n",
    "\n",
    "for run in runs:\n",
    "    files = fdb.df.query(f\"run == {run}\").index\n",
    "    t = rdb_df.loc[run]['type']\n",
    "    ts = 0\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        if t == 'alp':\n",
    "            plt.scatter(data[ds][t][run][file]['cal_ToE'], ts + data[ds][t][run][file]['timestamp'].nda, marker=\".\", alpha=0.006, s=1, color=cmap(i/len(files)))\n",
    "            plt.ylabel(\"Timestamp\")\n",
    "            plt.xlabel(\"T/E\")\n",
    "            ts += np.max(data[ds][t][run][file]['timestamp'].nda)\n",
    "        else:\n",
    "            plt.scatter(data[ds][t][file]['cal_ToE'], ts + data[ds][t][file]['timestamp'].nda, marker=\".\", alpha=0.006, s=1, color=cmap(i/len(files)))\n",
    "            plt.ylabel(\"Timestamp\")\n",
    "            plt.xlabel(\"T/E\")\n",
    "            ts += np.max(data[ds][t][file]['timestamp'].nda)\n",
    "\n",
    "    plt.xlim(-0.55, .55)\n",
    "    plt.title(f\"T/E over time - {t} Run {run}\")\n",
    "\n",
    "    ds = rdb_df.loc[run]['dataset']\n",
    "    rot = rdb_df.loc[run]['rotary']\n",
    "    lin = rdb_df.loc[run]['linear']\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    pgh.plot_hist(cal_ToE_hists[ds][run]/np.max(cal_ToE_hists[ds][run]), bins=cal_toe_bins, label=f'run {run}')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('T/E')\n",
    "    plt.title(f\"Dataset {ds} - Rotary {rot} Linear {lin}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = mpl.cm.get_cmap('rainbow')\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel('Normalized Count')\n",
    "plt.xlabel('Calibrated T/E')\n",
    "\n",
    "for run in runs:\n",
    "    files = fdb.df.query(f\"run == {run}\").index\n",
    "    t = rdb_df.loc[run]['type']\n",
    "    ts = 0\n",
    "\n",
    "    rot = rdb_df.loc[run]['rotary']\n",
    "    lin = rdb_df.loc[run]['linear']\n",
    "    src = rdb_df.loc[run]['source']\n",
    "\n",
    "    pgh.plot_hist(cal_ToE_hists[ds][run]/np.max(cal_ToE_hists[ds][run]), bins=cal_toe_bins, label=f'linear {lin}', color=cmap((run - runs[0])/len(runs)))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = mpl.cm.get_cmap('rainbow')\n",
    "\n",
    "for run in runs:\n",
    "    files = fdb.df.query(f\"run == {run}\").index\n",
    "    t = rdb_df.loc[run]['type']\n",
    "    ts = 0\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        if t == 'alp':\n",
    "            plt.scatter(data[ds][t][run][file]['cal_ToE'], ts + data[ds][t][run][file]['timestamp'].nda, marker=\".\", alpha=0.006, s=1, color=cmap(i/len(files)))\n",
    "            plt.ylabel(\"Timestamp\")\n",
    "            plt.xlabel(\"T/E\")\n",
    "            ts += np.max(data[ds][t][run][file]['timestamp'].nda)\n",
    "        else:\n",
    "            plt.scatter(data[ds][t][file]['cal_ToE'], ts + data[ds][t][file]['timestamp'].nda, marker=\".\", alpha=0.006, s=1, color=cmap(i/len(files)))\n",
    "            plt.ylabel(\"Timestamp\")\n",
    "            plt.xlabel(\"T/E\")\n",
    "            ts += np.max(data[ds][t][file]['timestamp'].nda)\n",
    "\n",
    "    plt.xlim(-0.55, .55)\n",
    "    plt.title(f\"T/E over time - {t} Run {run}\")\n",
    "\n",
    "    plt.figure()\n",
    "    pgh.plot_hist(cal_ToE_hists[ds][run]/np.max(cal_ToE_hists[ds][run]), bins=cal_toe_bins, label=f'run {run}')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('T/E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    files = fdb.df.query(f\"run == {run}\").index\n",
    "    t = rdb_df.loc[run]['type']\n",
    "    ts = 0\n",
    "\n",
    "    cmap = mpl.cm.get_cmap('rainbow')\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for file in files[:-1]:\n",
    "        if t == 'alp':\n",
    "            hist = np.histogram(data[ds][t][run][file]['cal_ToE'], bins=cal_toe_bins)[0]\n",
    "            pgh.plot_hist(hist/np.max(hist), bins=cal_toe_bins, label=f'cycle {fdb.df.loc[file][\"cycle\"]}', color=cmap(list(files).index(file)/len(files)))\n",
    "        else:\n",
    "            hist = np.histogram(data[ds][t][file]['cal_ToE'], bins=cal_toe_bins)[0]\n",
    "            pgh.plot_hist(hist/np.max(hist), bins=cal_toe_bins, label=f'cycle {fdb.df.loc[file][\"cycle\"]}', color=cmap(list(files).index(file)/len(files)))\n",
    "\n",
    "    #plt.xlim(0.2, 0.5)\n",
    "    #plt.ylim(0, 0.15)\n",
    "    ds = rdb_df.loc[run]['dataset']\n",
    "    rot = rdb_df.loc[run]['rotary']\n",
    "    lin = rdb_df.loc[run]['linear']\n",
    "\n",
    "    plt.title(f\"Dataset {ds} - Rotary {rot} Linear {lin}\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('T/E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveforms and Alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk Waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: Drifting T/E\n",
    "\n",
    "**Human Input**: Bulk cuts\n",
    "\n",
    "This will build a superpulse out of `num_wfs` (but you can change how many) waveforms in the bulk of the T/E distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bulk_cuts = {\n",
    "    0: {\n",
    "        494: f\"(trapEmax_ctc > {100 / rdb_df.loc[494, 'cal_constant']} and trapEmax_ctc < {500 / rdb_df.loc[494, 'cal_constant']}) or trapEmax_ctc > {1000 / rdb_df.loc[494, 'cal_constant']}\",\n",
    "        495: f\"(trapEmax_ctc > {100 / rdb_df.loc[495, 'cal_constant']} and trapEmax_ctc < {500 / rdb_df.loc[495, 'cal_constant']}) or trapEmax_ctc > {1000 / rdb_df.loc[495, 'cal_constant']}\"\n",
    "    },\n",
    "   1: {\n",
    "       520: f\"trapEmax_ctc > {400 / rdb_df.loc[520, 'cal_constant']}\",\n",
    "       521: f\"trapEmax_ctc > {400 / rdb_df.loc[521, 'cal_constant']}\",\n",
    "       522: f\"trapEmax_ctc > {400 / rdb_df.loc[522, 'cal_constant']}\",\n",
    "       523: f\"trapEmax_ctc > {400 / rdb_df.loc[523, 'cal_constant']}\",\n",
    "       524: f\"trapEmax_ctc > {400 / rdb_df.loc[524, 'cal_constant']}\"\n",
    "   }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_wfs = 500\n",
    "\n",
    "bulk_superpulse = {}\n",
    "bulk_wfs = {}\n",
    "bulk_energy = {}\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for ds, ds_df in rdb_df.groupby(by=\"dataset\"):\n",
    "    bulk_superpulse[ds] = {}\n",
    "    bulk_wfs[ds] = None\n",
    "    bulk_energy[ds] = None\n",
    "    for run in ds_df.query(\" type == 'bkg' \").index:\n",
    "        ToE_avg = np.average(pgh.get_bin_centers(toe_bins), weights=ToE_hists[ds][run])\n",
    "        ToE_fwhm, _ = pgh.get_fwhm(ToE_hists[ds][run], toe_bins)\n",
    "        \n",
    "        cut = f\" abs( ToE - {ToE_avg} ) < {ToE_fwhm * 0.1}\"\n",
    "        if ds in bulk_cuts and run in bulk_cuts[ds]:\n",
    "            cut += \" and \" + bulk_cuts[ds][run]\n",
    "        \n",
    "        dl.reset()\n",
    "        dl.set_files(f\"run == {run}\")\n",
    "        dl.set_cuts({\"hit\": cut})\n",
    "        dl.set_output(merge_files=True, columns=[\"waveform\", \"bl\", \"tp_50\", \"trapEmax_ctc\"])\n",
    "\n",
    "        el = dl.build_entry_list()\n",
    "        bulk_data = dl.load(el[:min(num_wfs, len(el))])\n",
    "        wfs = bulk_data['waveform']['values'].nda\n",
    "        bls = bulk_data['bl'].nda \n",
    "        subbed = np.subtract(wfs.T, bls).T\n",
    "        norm_wfs = subbed / subbed.max(axis = 1, keepdims = True)\n",
    "        \n",
    "        aligned_wfs = [norm_wfs[i][int(bulk_data['tp_50'].nda[i]/10)-500 : int(bulk_data['tp_50'].nda[i]/10)+500] for i in range(len(bulk_data))]\n",
    "                \n",
    "        bulk_superpulse[ds][run] = np.average(aligned_wfs, axis=0)\n",
    "        \n",
    "        if bulk_wfs[ds] is None:\n",
    "            bulk_wfs[ds] = aligned_wfs\n",
    "            bulk_energy[ds] = bulk_data[\"trapEmax_ctc\"].nda\n",
    "        else:\n",
    "            bulk_wfs[ds] += aligned_wfs\n",
    "            bulk_energy[ds] = np.concatenate((bulk_energy[ds], bulk_data[\"trapEmax_ctc\"].nda))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the superpulses\n",
    "plt.figure()\n",
    "plt.xlim(-100, 100)\n",
    "plt.title(\"Bulk Superpulses\")\n",
    "plt.xlabel(\"time - tp_50 [10 ns]\")\n",
    "plt.ylabel(\"ADC [arb]\")\n",
    "for ds in bulk_superpulse:\n",
    "    super_superpulse = np.average(np.array(list(bulk_superpulse[ds].values())), axis=0)\n",
    "    plt.plot(np.arange(-500, 500), super_superpulse, label=f\"Dataset {ds}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the superpulses run-by-run\n",
    "cmap_options = [\"spring\", \"winter\", \"terrain\", \"ocean\"]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim(-100, 100)\n",
    "plt.title(\"Bulk Superpulses\")\n",
    "plt.xlabel(\"time - tp_50 [10 ns]\")\n",
    "plt.ylabel(\"ADC [arb]\")\n",
    "for ds in bulk_superpulse:\n",
    "    cmap = mpl.cm.get_cmap(cmap_options[int(ds)])\n",
    "    for i, run in enumerate(bulk_superpulse[ds]):\n",
    "        plt.plot(np.arange(-500, 500), bulk_superpulse[ds][run], label=f\"DS {ds}, Run {run}\", color=cmap(i*0.2))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Reqs**: \"Bulk Waveforms\", and \"Parameter vs. Energy Plots\" is useful for setting cuts\n",
    "\n",
    "**Human Input**: Alpha cuts\n",
    "\n",
    "This will load waveforms that pass the given cuts. It will first build an entry list, and then build a superpulse from chunks. \n",
    "\n",
    "Specifying energy cuts is difficult - we want to specify them in terms of calibrated energies, which don't exist on disk. So we have to \"uncalibrate\" the energies in order to apply the cuts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alp_cuts = {\n",
    "    0: {\n",
    "        509: f\"ToE < { (-0.5 + 1) * rdb_df.loc[509, 'toe_mode']} and trapEmax_ctc < {500 / rdb_df.loc[509, 'cal_constant']} and trapEmax_ctc > {100 / rdb_df.loc[509, 'cal_constant']}\",\n",
    "        510: f\"dcr > 15 and trapEmax_ctc > {2000 / rdb_df.loc[510, 'cal_constant']} and trapEmax_ctc < {2500 / rdb_df.loc[510, 'cal_constant']}\",\n",
    "        # 511: f\"(dcr > 15 or ToE > { (1.125) * rdb_df.loc[511, 'toe_mode']}) and trapEmax_ctc > {1000 / rdb_df.loc[511, 'cal_constant']}\",\n",
    "        512: f\"ToE > { (0.0625 + 1) * rdb_df.loc[512, 'toe_mode']} and trapEmax_ctc > {1500 / rdb_df.loc[512, 'cal_constant']} and trapEmax_ctc < {2500 / rdb_df.loc[512, 'cal_constant']}\",\n",
    "        # 513: f\"(dcr > 15 or ToE > { (1.125) * rdb_df.loc[513, 'toe_mode']}) and trapEmax_ctc > {1000 / rdb_df.loc[513, 'cal_constant']}\",\n",
    "        514: f\"ToE > { (0.25 + 1) * rdb_df.loc[514, 'toe_mode']} and trapEmax_ctc > {1000 / rdb_df.loc[514, 'cal_constant']}\"\n",
    "    },\n",
    "   1: {\n",
    "       525: f\"dcr > 15 and trapEmax_ctc > {1500 / rdb_df.loc[525, 'cal_constant']}\",\n",
    "       # 526: f\"(dcr > 8 or ToE > { (1.125) * rdb_df.loc[526, 'toe_mode']}) and trapEmax_ctc > {500 / rdb_df.loc[510, 'cal_constant']}\",\n",
    "       531: f\"ToE > { (0.09 + 1) * rdb_df.loc[531, 'toe_mode']} and trapEmax_ctc > {800 / rdb_df.loc[531, 'cal_constant']}\",\n",
    "       532: f\"ToE > { (0.125 + 1) * rdb_df.loc[532, 'toe_mode']} and trapEmax_ctc > {500 / rdb_df.loc[532, 'cal_constant']} and trapEmax_ctc < {1500 / rdb_df.loc[532, 'cal_constant']}\",\n",
    "       534: f\"ToE > { (0.125 + 1) * rdb_df.loc[534, 'toe_mode']} and trapEmax_ctc > {400 / rdb_df.loc[534, 'cal_constant']}\"\n",
    "   }\n",
    "}\n",
    "\n",
    "chunk_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alp_superpulse = {}\n",
    "alp_energy = {}\n",
    "alp_dcr = {}\n",
    "alp_toe = {}\n",
    "\n",
    "for ds in alp_cuts:\n",
    "    alp_superpulse[ds] = {}\n",
    "    alp_dcr[ds] = {}\n",
    "    alp_toe[ds] = {}\n",
    "    alp_energy[ds] = {}\n",
    "    for run in alp_cuts[ds]: \n",
    "        dl.reset()\n",
    "        dl.set_files(f\"run == {run}\")\n",
    "        dl.set_cuts({\"hit\": alp_cuts[ds][run]})\n",
    "        dl.set_output(merge_files=True, columns=[\"waveform\", \"bl\", \"dcr\", \"trapEmax_ctc\", \"ToE\", \"tp_50\"])\n",
    "\n",
    "        el = dl.build_entry_list()\n",
    "        for alp_data in dl.next(el, chunk_size=chunk_size):\n",
    "            wfs = alp_data['waveform']['values'].nda\n",
    "            bls = alp_data['bl'].nda \n",
    "            alp_data['tp_50'].nda = np.nan_to_num(alp_data['tp_50'].nda)\n",
    "            subbed = np.subtract(wfs.T, bls).T\n",
    "            norm_wfs = subbed / subbed.max(axis = 1, keepdims = True)\n",
    "            aligned_wfs = []\n",
    "            for i in range(len(alp_data)):\n",
    "                tp50 = int(alp_data['tp_50'].nda[i]/10)\n",
    "                if tp50 < 500 or tp50 > len(wfs[0])-500:\n",
    "                    continue\n",
    "                aligned_wfs.append(norm_wfs[i][tp50-500 : tp50+500])\n",
    "            aligned_wfs = np.array(aligned_wfs)\n",
    "            \n",
    "            if run not in alp_superpulse[ds]:\n",
    "                alp_superpulse[ds][run] = np.sum(aligned_wfs, axis=0)\n",
    "                alp_dcr[ds][run] = alp_data['dcr'].nda\n",
    "                alp_toe[ds][run] = alp_data['ToE'].nda\n",
    "                alp_energy[ds][run] = alp_data['trapEmax_ctc'].nda * rdb_df.loc[run, 'cal_constant']\n",
    "            else:\n",
    "                alp_superpulse[ds][run] += np.sum(aligned_wfs, axis=0)\n",
    "                alp_dcr[ds][run] = np.append( alp_dcr[ds][run], alp_data['dcr'].nda )\n",
    "                alp_toe[ds][run] = np.append( alp_toe[ds][run], alp_data['ToE'].nda )\n",
    "                alp_energy[ds][run] = np.append( alp_energy[ds][run], alp_data['trapEmax_ctc'].nda * rdb_df.loc[run, 'cal_constant'] )\n",
    "        alp_superpulse[ds][run] /= len(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the superpulses run-by-run\n",
    "cmap_options = [\"rainbow\", \"rainbow\", \"terrain\", \"ocean\"]\n",
    "# style = ['solid', 'dashed']\n",
    "\n",
    "color=[\"Red\", \"royalblue\", \"lime\", \"darkviolet\"]\n",
    "\n",
    "for ds in alp_superpulse:\n",
    "    plt.figure()\n",
    "    plt.xlim(-100, 100)\n",
    "    plt.ylim(-0.3, 1.1)\n",
    "    plt.title(f\"Alpha Superpulses - Dataset {ds} \")\n",
    "    plt.xlabel(\"time - tp50 [10 ns]\")\n",
    "    plt.ylabel(\"ADC [arb]\")\n",
    "    legend = 0\n",
    "    for i, wf in enumerate(bulk_wfs[ds]):\n",
    "        if ds == 0 and bulk_energy[ds][i] < 500:\n",
    "            plt.plot(np.arange(-500, 500), wf, color='gold', linewidth=0.5, alpha=0.05)\n",
    "            if type(legend) is int and legend < 5:\n",
    "                legend += 1\n",
    "            elif type(legend) is int:\n",
    "                plt.plot(np.arange(-500, 500), wf, color='gold', label='Background < 500 keV', linewidth=1, alpha=1)\n",
    "                legend = False\n",
    "        else:\n",
    "            plt.plot(np.arange(-500, 500), wf, color='lightgrey', linewidth=0.5, alpha=0.05)\n",
    "    plt.plot(np.arange(-500, 500), wf, color='lightgrey', label='Background', linewidth=1, alpha=1)\n",
    "        \n",
    "    for i, run in enumerate(alp_superpulse[ds]):\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "        \n",
    "        cmap = mpl.cm.get_cmap(cmap_options[ds])\n",
    "        \n",
    "        # for n in range(10):\n",
    "        #     plt.plot(np.arange(-500, 500), alp_superpulse[ds][run][n*10], color=cmap(i*0.2))\n",
    "        plt.plot(np.arange(-500, 500), alp_superpulse[ds][run], label=f\"Linear {lin}\", color=color[i], linewidth=1)\n",
    "        \n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the superpulses run-by-run\n",
    "cmap_options = [\"rainbow\", \"rainbow\", \"terrain\", \"ocean\"]\n",
    "# style = ['solid', 'dashed']\n",
    "\n",
    "\n",
    "\n",
    "for ds in alp_superpulse:\n",
    "    for i, run in enumerate(alp_superpulse[ds]):\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "        plt.figure()\n",
    "        plt.xlim(-100, 100)\n",
    "        plt.title(f\"Alpha Superpulses - Dataset {ds} Linear {lin}\")\n",
    "        plt.xlabel(\"time - tp50 [10 ns]\")\n",
    "        plt.ylabel(\"ADC [arb]\")\n",
    "\n",
    "        for wf in bulk_wfs[ds]:\n",
    "            plt.plot(np.arange(-500, 500), wf, color='lightgrey', linewidth=0.5, alpha=0.05)\n",
    "        plt.plot(np.arange(-500, 500), wf, color='lightgrey', label='Background', linewidth=1, alpha=1)\n",
    "        \n",
    "        cmap = mpl.cm.get_cmap(cmap_options[ds])\n",
    "        \n",
    "        # for n in range(10):\n",
    "        #     plt.plot(np.arange(-500, 500), alp_superpulse[ds][run][n*10], color=cmap(i*0.2))\n",
    "        plt.plot(np.arange(-500, 500), alp_superpulse[ds][run], label=f\"Linear {lin}\", color=cmap(i*0.2), linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the superpulses run-by-run\n",
    "cmap_options = [\"spring\", \"winter\", \"terrain\", \"ocean\"]\n",
    "style = ['solid', 'dashed']\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim(-100, 100)\n",
    "plt.title(\"Alpha Superpulses - By Run\")\n",
    "plt.xlabel(\"time - tp50 [10 ns]\")\n",
    "plt.ylabel(\"ADC [arb]\")\n",
    "\n",
    "for ds in alp_superpulse:\n",
    "    cmap = mpl.cm.get_cmap(cmap_options[ds])\n",
    "    super_superpulse = np.average(np.array(list(bulk_superpulse[ds].values())), axis=0)\n",
    "    plt.plot(np.arange(-500, 500), super_superpulse, label=f\"Dataset {ds} Bkg\", color='black', linestyle=style[ds])\n",
    "    for i, run in enumerate(alp_superpulse[ds]):\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "        plt.plot(np.arange(-500, 500), alp_superpulse[ds][run], label=f\"DS {ds}, Linear {lin}\", color=cmap(i*0.2))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the superpulses for each dataset\n",
    "cmap_options = [\"spring\", \"winter\", \"terrain\", \"ocean\"]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim(-100, 100)\n",
    "plt.title(\"Alpha Superpulses - By Dataset\")\n",
    "plt.xlabel(\"time - tp50 [10 ns]\")\n",
    "plt.ylabel(\"ADC [arb]\")\n",
    "\n",
    "for ds in alp_superpulse:\n",
    "    super_superpulse = np.average(np.array(list(alp_superpulse[ds].values())), axis=0)\n",
    "    plt.plot(np.arange(-500, 500), super_superpulse, label=f\"Dataset {ds}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the superpulses for each dataset\n",
    "colors = ['blue', 'orange']\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim(-100, 100)\n",
    "plt.title(\"Bkg and Alpha Superpulses - By Dataset\")\n",
    "plt.xlabel(\"time - tp50 [10 ns]\")\n",
    "plt.ylabel(\"ADC [arb]\")\n",
    "\n",
    "for ds in alp_superpulse:\n",
    "    super_superpulse = np.average(np.array(list(alp_superpulse[ds].values())), axis=0)\n",
    "    bkg_superpulse = np.average(np.array(list(bulk_superpulse[ds].values())), axis=0)\n",
    "    plt.plot(np.arange(-500, 500), super_superpulse, label=f\"Dataset {ds}\", color=colors[ds])\n",
    "    plt.plot(np.arange(-500, 500), bkg_superpulse, label=f\"Dataset {ds} Bkg\", color=colors[ds], linestyle='dashed')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Par vs. E After Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_ebins = np.linspace(0, 4000, 2000)\n",
    "plot_toebins = np.linspace(-1, 1, 200)\n",
    "plot_dcrbins = np.linspace(-50, 200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bkg_cuts = {}\n",
    "\n",
    "print(f\"Loading dataset {ds}\")\n",
    "if ds not in bkg_cuts.keys():\n",
    "    bkg_cuts[ds] = {}\n",
    "for t, t_df in ds_df.groupby(by=\"type\"):\n",
    "    print(t)\n",
    "    if t == \"alp\":\n",
    "        continue\n",
    "    else:\n",
    "        for run in t_df.index:\n",
    "            print(run)\n",
    "            dl.reset()\n",
    "            dl.set_files(f\"run == {run}\")\n",
    "            dl.set_output(merge_files=True, columns=par_names)\n",
    "            dl.set_cuts({\"hit\": f\"( dcr > 15 or ToE > { (1.125) * rdb_df.loc[run, 'toe_mode']} ) and trapEmax_ctc > {1000 / rdb_df.loc[run, 'cal_constant']}\"})\n",
    "            el = dl.build_entry_list()\n",
    "            d = dl.load(el.reset_index(drop=True))\n",
    "            bkg_cuts[ds][run] = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = copy.copy(mpl.colormaps['coolwarm'])\n",
    "    \n",
    "for ds in alp_dcr:\n",
    "    for run in alp_dcr[ds]: \n",
    "        rot = rdb_df.loc[run]['rotary']\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(f\"Alpha DCR, Dataset {ds} Rotary {rot}, Linear {lin}\")\n",
    "        plt.xlabel(\"Energy [keV]\")\n",
    "        plt.ylabel(f\"DCR [arb]\")\n",
    "\n",
    "        alp_hist = np.histogram2d(alp_energy[ds][run], alp_dcr[ds][run], bins=(cal_ebins, dcr_bins))[0]\n",
    "        \n",
    "        # hist_unc = np.sqrt(alp_hist/(data[ds][\"alp\"][run][\"rt\"]**2) + bkg_hist/(data[ds][\"bkg\"][\"rt\"]**2) )        \n",
    "            \n",
    "        # alp_hist /= data[ds][\"alp\"][run][\"rt\"]\n",
    "        # alp_hist -= bkg_hist\n",
    "\n",
    "        # alp_hist = alp_hist/hist_unc\n",
    "        \n",
    "        # lim = np.max(alp_hist)/10\n",
    "        plt.pcolor(cal_ebins, dcr_bins, alp_hist.T, #cmap=cmap, norm=colors.LogNorm())\n",
    "                   cmap=cmap, norm=colors.SymLogNorm(linthresh=0.00001, vmin=-1e1, vmax=1e1))\n",
    "        \n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n",
    "    \n",
    "for ds in alp_dcr:\n",
    "    plt.figure()\n",
    "    plt.title(f\"Alpha DCR, Dataset {ds} Rotary {rot}\")\n",
    "    plt.xlabel(\"Energy [keV]\")\n",
    "    plt.ylabel(f\"DCR [arb]\")\n",
    "    alp_hist = None\n",
    "    for i, run in enumerate(alp_dcr[ds]): \n",
    "        rot = rdb_df.loc[run]['rotary']\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "\n",
    "        # alp_hist = np.histogram2d(alp_energy[ds][run], alp_dcr[ds][run], bins=(cal_ebins, dcr_bins))[0]\n",
    "        \n",
    "        # hist_unc = np.sqrt(alp_hist/(data[ds][\"alp\"][run][\"rt\"]**2) + bkg_hist/(data[ds][\"bkg\"][\"rt\"]**2) )        \n",
    "            \n",
    "        # alp_hist /= data[ds][\"alp\"][run][\"rt\"]\n",
    "        # alp_hist -= bkg_hist\n",
    "\n",
    "        # alp_hist = alp_hist/hist_unc\n",
    "        \n",
    "        # lim = np.max(alp_hist)/10\n",
    "        plt.hist2d(alp_energy[ds][run], alp_dcr[ds][run], bins=(plot_ebins, plot_dcrbins), cmap=cmap[i], norm=colors.LogNorm(vmin=1e-1))\n",
    "\n",
    "        # plt.colorbar()\n",
    "    # plt.xlim(0, 3000)\n",
    "    # plt.ylim(-30, 60)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha T/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = copy.copy(mpl.colormaps['coolwarm'])\n",
    "    \n",
    "for ds in alp_toe:\n",
    "    # Make the background histogram\n",
    "    # bkg_hist = None\n",
    "    # for run in bkg_cuts[ds]:\n",
    "    #     par = 'ToE'\n",
    "\n",
    "#         par_vals = (bkg_cuts[ds][run][par] / rdb_df.loc[run, 'toe_mode']) - 1\n",
    "\n",
    "#         if bkg_hist is None:\n",
    "#             bkg_hist = np.histogram2d(bkg_cuts[ds][run]['trapEmax_ctc']/rdb_df.loc[run, 'cal_constant'], par_vals, bins=(cal_ebins, cal_toe_bins))[0]\n",
    "#         else:\n",
    "#             bkg_hist += np.histogram2d(bkg_cuts[ds][run]['trapEmax_ctc']/rdb_df.loc[run, 'cal_constant'], par_vals, bins=(cal_ebins, cal_toe_bins))[0]\n",
    "#     bkg_hist /= data[ds][\"bkg\"][\"rt\"]\n",
    "\n",
    "    for run in alp_toe[ds]: \n",
    "        rot = rdb_df.loc[run]['rotary']\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(f\"Alpha T/E, Dataset {ds} Rotary {rot}, Linear {lin}\")\n",
    "        plt.xlabel(\"Energy [keV]\")\n",
    "        plt.ylabel(f\"T/E (Calibrated) [arb]\")\n",
    "\n",
    "        alp_hist = np.histogram2d(alp_energy[ds][run], (alp_toe[ds][run] / rdb_df.loc[run, 'toe_mode']) - 1, bins=(cal_ebins, cal_toe_bins))[0]\n",
    "        \n",
    "#         hist_unc = np.sqrt(alp_hist/(data[ds][\"alp\"][run][\"rt\"]**2) + bkg_hist/(data[ds][\"bkg\"][\"rt\"]**2) )        \n",
    "            \n",
    "#         alp_hist /= data[ds][\"alp\"][run][\"rt\"]\n",
    "#         alp_hist -= bkg_hist\n",
    "\n",
    "#         alp_hist = alp_hist/hist_unc\n",
    "        \n",
    "        # lim = -1 * np.min(alp_hist)/10\n",
    "        plt.pcolor(cal_ebins, cal_toe_bins, alp_hist.T, #cmap=cmap, norm=colors.LogNorm())\n",
    "                   cmap=cmap, norm=colors.SymLogNorm(linthresh=0.00001, vmin=-10, vmax=10))\n",
    "        \n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n",
    "    \n",
    "for ds in alp_dcr:\n",
    "    plt.figure()\n",
    "    plt.title(f\"Alpha T/E, Dataset {ds} Rotary {rot}\")\n",
    "    plt.xlabel(\"Energy [keV]\")\n",
    "    plt.ylabel(f\"T/E (calibrated [arb]\")\n",
    "    alp_hist = None\n",
    "    for i, run in enumerate(alp_dcr[ds]): \n",
    "        rot = rdb_df.loc[run]['rotary']\n",
    "        lin = rdb_df.loc[run]['linear']\n",
    "\n",
    "        # alp_hist = np.histogram2d(alp_energy[ds][run], alp_dcr[ds][run], bins=(cal_ebins, dcr_bins))[0]\n",
    "        \n",
    "        # hist_unc = np.sqrt(alp_hist/(data[ds][\"alp\"][run][\"rt\"]**2) + bkg_hist/(data[ds][\"bkg\"][\"rt\"]**2) )        \n",
    "            \n",
    "        # alp_hist /= data[ds][\"alp\"][run][\"rt\"]\n",
    "        # alp_hist -= bkg_hist\n",
    "\n",
    "        # alp_hist = alp_hist/hist_unc\n",
    "        \n",
    "        # lim = np.max(alp_hist)/10\n",
    "        plt.hist2d(alp_energy[ds][run], (alp_toe[ds][run] / rdb_df.loc[run, 'toe_mode']) - 1, bins=(plot_ebins, plot_toebins), cmap=cmap[i], norm=colors.LogNorm())\n",
    "\n",
    "        # plt.colorbar()\n",
    "    # plt.xlim(0, 3000)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygama-dev",
   "language": "python",
   "name": "pygama-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
