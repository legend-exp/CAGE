{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854b78b0-626a-4235-aea8-d6bcb4c326f1",
   "metadata": {},
   "source": [
    "# NERSC allocation estimate\n",
    "\n",
    "Jason requests we put in for \"3x our current CAGE usage\"\n",
    "\n",
    "https://legend-exp.atlassian.net/wiki/spaces/LEGEND/pages/471924737/NERSC+Allocation+Request+for+2022\n",
    "\n",
    "Clint, Sep 2021\n",
    "\n",
    "Reference job_id: 47129665\n",
    "- Processing of run 341, cycles 2348-2377.\n",
    "- Start: Fri Sep 17 08:01:35 PDT 2021\n",
    "- Stop: Fri Sep 17 12:44:22 PDT 2021\n",
    "\n",
    "Total time: 4 hrs, 43 minutes.  (Shared queue, 1 CPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc6a04bb-f7e2-44bc-8265-db0ef79d2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095573be-9cac-4deb-9af0-1a9dd2dc0ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/file_keys']\n"
     ]
    }
   ],
   "source": [
    "f_db = '../fileDB.h5'\n",
    "\n",
    "with pd.HDFStore(f_db) as pf:\n",
    "    print(pf.keys())\n",
    "    \n",
    "df_fileDB = pd.read_hdf(f_db)\n",
    "\n",
    "# display(df_fileDB)\n",
    "df_fileDB.columns\n",
    "\n",
    "view_cols = ['run', 'cycle', 'YYYY', 'mm', 'dd', 'runtime', 'daq_gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea4ce21c-d667-46cc-8550-ac316123f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total size of dataset taken to date in 2021, based on 'daq_gb'\n",
    "\n",
    "df_ref = df_fileDB.query('cycle >= 2348 and cycle <= 2377').copy()\n",
    "\n",
    "# 1630479600 is Sep 1 in unix time\n",
    "df_data = df_fileDB.query('YYYY == 2021 and startTime < 1630479600').copy()\n",
    "\n",
    "# display(df_ref[view_cols])\n",
    "# display(df_data[view_cols])\n",
    "\n",
    "du_ref = df_ref['daq_gb'].sum()\n",
    "du_data = df_data['daq_gb'].sum()\n",
    "# print(du_ref, du_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0748798-5e75-4e5f-8c03-f251345c64d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09417280412633992\n",
      "CPU hours used thru August: 178.754 , thru December: 268.132\n",
      "Allocation for 2022 assuming 3x usage: 804.395\n",
      "Disk space used in 2021: 5.694 TB\n",
      "Requested disk allocation for 2022: 20.500 TB\n"
     ]
    }
   ],
   "source": [
    "# compute CPU hours used to date (Jan -- Sep 2021)\n",
    "\n",
    "# usage of reference job (CPU hrs / GB)\n",
    "t_ref = 4 + 43/60\n",
    "\n",
    "burn_rate = t_ref / du_ref\n",
    "\n",
    "print(burn_rate)\n",
    "\n",
    "# get usage through august and extrapolate to all of 2021\n",
    "usage_aug = burn_rate * du_data\n",
    "usage_2021 = usage_aug / (8/12)\n",
    "\n",
    "print(f'CPU hours used thru August: {usage_aug:.3f} , thru December: {usage_2021:.3f}')\n",
    "\n",
    "usage_2022 = usage_2021 * 3\n",
    "\n",
    "print(f'Allocation for 2022 assuming 3x usage: {usage_2022:.3f}')\n",
    "\n",
    "\n",
    "# now compute expected disk usage for 2022.  assume total = daq * 2 (daq+raw makes up most of this).\n",
    "# we are also going to GZIP the ORCA files and eventually compress the raw LH5, but\n",
    "# let's do this assuming that neither of those things are implemented.\n",
    "\n",
    "diskspace_2021 = 2 * du_data / (8/12) / 1000\n",
    "print(f'Disk space used in 2021: {diskspace_2021:.3f} TB')\n",
    "\n",
    "# assume we take 20% more data\n",
    "diskspace_2022 = 1.2 * diskspace_2021\n",
    "\n",
    "# apply Jason's request that we ask for 3x what we think we'll use\n",
    "diskspace_2022 = 3 * diskspace_2022\n",
    "\n",
    "\n",
    "print(f'Requested disk allocation for 2022: {diskspace_2022:.3f} TB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ef84e-56dd-47fc-b059-d4806477f3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legend-base",
   "language": "python",
   "name": "legend-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
